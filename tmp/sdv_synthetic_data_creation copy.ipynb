{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDV SYNTHETIC DATA GENERATION\n",
    "\n",
    "## LOAD PREPROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# create folder\n",
    "tmp_folder = \"./tmp_folder\"\n",
    "diabetes = pd.read_parquet(os.path.join(tmp_folder,\"preprocessed_file.parquet\"),engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE SYNTHETIZER & SYNTHETIC DATA WITH SDV\n",
    "\n",
    "### Create Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataframe into`SingleTableMetadata` data type \n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "def create_metadata(df):\n",
    "    \"\"\"\n",
    "    SingleTableMetadata type data creation. Obtains information directly from original dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        SingleTableMetadata: metadata to create synthetic data\n",
    "    \"\"\"\n",
    "    # Automatically detect metadata from the actual DataFrame\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(df)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# create metadata\n",
    "metadata = create_metadata(diabetes)\n",
    "\n",
    "# Check if metadata has been correctly generated\n",
    "print(metadata)\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetizer and synthetic data\n",
    "\n",
    "#### Check numeric data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric columns\n",
    "num_cols = diabetes.select_dtypes(include='int64').columns.to_list()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# plot their distribution\n",
    "for col in num_cols:\n",
    "    # Plot histogram\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Get unique values count for binning (useful for integer columns)\n",
    "    unique_values = diabetes[col].nunique()\n",
    "    \n",
    "    # Set the number of bins based on unique values or a minimum threshold for better visualization\n",
    "    if unique_values < 30:\n",
    "        bins = unique_values  # Use number of unique values if less than 30\n",
    "    else:\n",
    "        bins = 30  # Default to 30 bins if more than 30 unique values\n",
    "    \n",
    "    \n",
    "    ax.hist(diabetes[col], bins= bins)\n",
    "    \n",
    "    # Set xticks based on min and max values in the column\n",
    "    col_min, col_max = diabetes[col].min(), diabetes[col].max()\n",
    "    \n",
    "    # Adjust step size for xticks dynamically (if range is small, step=1, else larger step)\n",
    "    if col_max - col_min < 30:\n",
    "        step_size = 1\n",
    "    else:\n",
    "        step_size = (col_max - col_min) // 10  # Step size as a fraction of the range\n",
    "\n",
    "    # Set the xticks on the axis\n",
    "    ax.set_xticks(np.arange(col_min, col_max + step_size, step_size))\n",
    "\n",
    "    # Adjust & show the plot\n",
    "    ax.set_title(f'Distribution of {col}')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define numeric data distribution for synthetizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sdv.single_table import GaussianCopulaSynthesizer\n",
    "\n",
    "# Specify the distribution for numerical columns\n",
    "numerical_distributions = {\n",
    "    'time_in_hospital': 'beta',  # Right-skewed integer distribution\n",
    "    'num_lab_procedures': 'norm', # Normal distribution\n",
    "    'num_procedures': 'beta',  # Right-skewed\n",
    "    'num_medications': 'norm', # Normal distribution\n",
    "    'number_outpatient': 'beta',  # Right-skewed\n",
    "    'number_emergency': 'beta',  # Right-skewed\n",
    "    'number_inpatient': 'beta',  # Right-skewed\n",
    "    'number_diagnoses': 'gamma' # Left-skewed\n",
    "}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetizer and synthetic data \n",
    "def create_synthetizer (md, df):\n",
    "    \"\"\"\n",
    "    Creates synthetizer, trains synthetizer with real data and creates new \n",
    "    synthetic data.\n",
    "    \n",
    "    Parameters:\n",
    "        md (SingleTableMetadata): Metadata of DataFrame.\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        sinthetizer (GaussianCopulaSynthesizer): returns trained synthetizer.\n",
    "    \"\"\"\n",
    "\n",
    "    # create synthetizer\n",
    "    synthesizer = GaussianCopulaSynthesizer(\n",
    "        md, \n",
    "        enforce_min_max_values=True,\n",
    "        enforce_rounding=True#,  # Ensure integer values are generated\n",
    "        #numerical_distributions= num_distribution\n",
    "    )\n",
    "    \n",
    "    # train data to learn from real data\n",
    "    synthesizer.fit(\n",
    "        data = df\n",
    "    )\n",
    "\n",
    "    return synthesizer    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data with synthetizer\n",
    "def create_synth_data (df, md):\n",
    "    \"\"\"\n",
    "    Creates synthetic data using metadata and specific numerical distribution\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        md (SingleTableMetadata): Metadata of DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        synthetic_data (pd.DataFrame): new synthetic data.\n",
    "        synthesizer (GaussianCopulaSynthesizer): trained synthetizer.\n",
    "    \"\"\"\n",
    "    # create synthetizer\n",
    "    synthesizer = create_synthetizer (md, df)\n",
    "    \n",
    "    # create new synth data\n",
    "    synthetic_data = synthesizer.sample(\n",
    "        num_rows=df.shape[0]\n",
    "    )\n",
    "    \n",
    "    return synthetic_data, synthesizer\n",
    "\n",
    "# obtain synthetic data\n",
    "#synthetic_data, synthesizer = create_synth_data(diabetes, metadata, numerical_distributions)\n",
    "synthetic_data, synthesizer = create_synth_data(diabetes, metadata)\n",
    "\n",
    "# print result\n",
    "synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "\n",
    "quality_report = evaluate_quality(\n",
    "    diabetes,\n",
    "    synthetic_data,\n",
    "    metadata\n",
    ")\n",
    "\n",
    "print(f\"Quality of synthetic data is: {quality_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE SYNTHETIC DATA AND VALIDATE\n",
    "\n",
    "### Compare dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Real dimension: {diabetes.shape}\")\n",
    "print(f\"Synth dimension: {synthetic_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare general data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information from both datasets\n",
    "real_data_info = pd.DataFrame({\n",
    "    'Column': diabetes.columns,\n",
    "    'Real Non-Null Count':diabetes.notnull().sum()\n",
    "})\n",
    "\n",
    "# For synthetic data\n",
    "synthetic_data_info = pd.DataFrame({\n",
    "    'Column': synthetic_data.columns,\n",
    "    'Synthetic Non-Null Count':synthetic_data.notnull().sum()\n",
    "})\n",
    "\n",
    "# Merge the two DataFrames on the 'Column' name\n",
    "comparison = pd.merge(real_data_info, synthetic_data_info, on='Column', how='outer')\n",
    "\n",
    "# Print comparison table\n",
    "print(\"Comparison of Real and Synthetic Data:\")\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data anonymization\n",
    "\n",
    "Check first N rows and their sensible columns values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect sensible columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify identity sensible data: \n",
    "sensitive_columns = ['race', 'gender', 'age', 'admission_type_id','discharge_disposition_id','admission_source_id','payer_code']\n",
    "print(f\"\\nSensitive columns: {sensitive_columns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sensible data anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Real: {diabetes[sensitive_columns].head()}\")\n",
    "print(f\"\\nSynthetic: {synthetic_data[sensitive_columns].head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for numeric data correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CORRELATION MATRIX\n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "corr_r = diabetes.corr()\n",
    "corr_s = synthetic_data.corr()\n",
    "sns.heatmap(corr_r, \n",
    "            xticklabels=corr_r.columns.values,\n",
    "            yticklabels=corr_r.columns.values,\n",
    "            cmap=\"Blues\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[0])\n",
    "sns.heatmap(corr_s, \n",
    "            xticklabels=corr_s.columns.values,\n",
    "            yticklabels=corr_s.columns.values,\n",
    "            cmap=\"Greens\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[1])\n",
    "ax[0].set_title(\"REAL\")\n",
    "ax[1].set_title(\"SYNTH\")\n",
    "plt.tight_layout()     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save synthetic data\n",
    "synthetic_data.to_parquet(os.path.join(tmp_folder,\"synthetic_data.parquet\"),engine=\"pyarrow\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save synthetizer:\n",
    "import pickle\n",
    "\n",
    "with open(\"synthesizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(my_synth, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
