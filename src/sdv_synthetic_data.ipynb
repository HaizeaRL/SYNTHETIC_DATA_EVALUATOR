{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDV SYNTHETIC DATA GENERATION\n",
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "'''# metadata \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.variables) '''\n",
    "  \n",
    "# fetch dataset \n",
    "diabetes_130_us_hospitals_for_years_1999_2008 = fetch_ucirepo(id=296) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = diabetes_130_us_hospitals_for_years_1999_2008.data.features \n",
    "y = diabetes_130_us_hospitals_for_years_1999_2008.data.targets \n",
    "\n",
    "# create complete real_data\n",
    "diabetes = pd.DataFrame(X)\n",
    "diabetes[\"readmitted\"] = y\n",
    "\n",
    "# visualize data\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE & PREPROCESS REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Dimension: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect sensitive columns by intuition by their name\n",
    "print(f\"\\columns: {diabetes.columns}\\n\")\n",
    "\n",
    "# identify identity sensible data: \n",
    "sensitive_column_names = ['race', 'gender', 'weight', 'admission_type_id','discharge_disposition_id','admission_source_id','payer_code', 'medical_specialty']\n",
    "print(f\"\\nSensitive columns: {sensitive_column_names}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check columns values & distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE COLUMN: check columns values & distribution\n",
    "def visualize_columns_distributions(df):\n",
    "    for col in df.columns:\n",
    "        print(f\"\\n\\nColumn: {col}\")\n",
    "\n",
    "        # Get value counts of data\n",
    "        val_counts = df[col].value_counts(dropna = False)   \n",
    "\n",
    "        # prepare to print more pretty way\n",
    "        counts_df = pd.DataFrame({'Items': val_counts})    \n",
    "\n",
    "        # Print \n",
    "        print(counts_df)\n",
    "    \n",
    "# call to columns_distibution function\n",
    "visualize_columns_distributions(diabetes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generalize 'Nan' race values to 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize Nan race as 'Other'\n",
    "import numpy as np\n",
    "diabetes.loc[diabetes[\"race\"].isin([np.nan ,'Other']), \"race\"] = \"Other\"\n",
    "\n",
    "# validate change\n",
    "diabetes.race.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Remove 'Unknown/Invalid' gender values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Unknown/Invalid' # only 3 registry, not possible to define gender, best option would be to remove them \n",
    "diabetes[diabetes['gender'] == 'Unknown/Invalid'] \n",
    "\n",
    "# removing  'Unknown/Invalid' gender data\n",
    "print(f\"Shape before drop: {diabetes.shape}\")\n",
    "diabetes = diabetes.drop(diabetes[diabetes[\"gender\"] == 'Unknown/Invalid'].index)\n",
    "\n",
    "# validating results (only 3 less)\n",
    "print(f\"Shape after drop: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check for null values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls per columns (percentage)\n",
    "diabetes.isna().sum() * 100 / len(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Drop \"weight\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove weight column form dataframe 96.858387% null values\n",
    "print(f\"Columns before remove {len(diabetes.columns)}\")\n",
    "diabetes = diabetes.drop('weight', axis=1)\n",
    "print(f\"Columns after remove {len(diabetes.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check for variability\n",
    "\n",
    "Columns that have only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns without variability\n",
    "def columns_without_variability(df):    \n",
    "    \"\"\"\n",
    "    Function that is responsible to determine which columnns has no variability (those which has only 1 value).    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        list(): list of variables without variability.\n",
    "    \"\"\"    \n",
    "    sobran = []\n",
    "\n",
    "    cols = df.columns\n",
    "    for col in cols:\n",
    "        if len(df[col].unique()) < 2:\n",
    "            sobran.append(col)\n",
    "\n",
    "    return sobran\n",
    "\n",
    "# obtener listado de columnas sin variabilidad en una lista\n",
    "cols_without_variability = columns_without_variability(diabetes)\n",
    "\n",
    "# remove columns without variabitly\n",
    "print(f\"Columns without variability: {cols_without_variability}\")\n",
    "print(f\"Columns before remove {len(diabetes.columns)}\")\n",
    "diabetes = diabetes.drop(columns = cols_without_variability)\n",
    "print(f\"Columns after remove {len(diabetes.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns that have more than one value, but only a single instance for one of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_single_value_entries(df):\n",
    "    rows_to_check = []  # List to hold the rows matching the criteria\n",
    "    cols_to_check = []\n",
    "    for col in df.columns:\n",
    "        # Get the value counts for the column\n",
    "        value_counts = df[col].value_counts()\n",
    "\n",
    "        # Check if exactly one value has a count of 1\n",
    "        if (value_counts == 1).sum() == 1:\n",
    "            # Get the value that appears exactly once\n",
    "            single_value = value_counts[value_counts == 1].index[0]\n",
    "            # add column name\n",
    "            cols_to_check.append(col)\n",
    "            \n",
    "            # Select rows where this single value appears\n",
    "            matching_rows = df[df[col] == single_value]\n",
    "            \n",
    "            # Append these rows to the list\n",
    "            rows_to_check.append(matching_rows)\n",
    "\n",
    "    # Concatenate all the matching rows into a single dataframe (if needed)\n",
    "    result_df = pd.concat(rows_to_check, ignore_index=True) if rows_to_check else pd.DataFrame()\n",
    "\n",
    "    return result_df,cols_to_check\n",
    "\n",
    "# determine single value entries\n",
    "matching_rows_df,cols_to_check = determine_single_value_entries(diabetes)\n",
    "\n",
    "# check data relevancy\n",
    "for col in cols_to_check:\n",
    "    value_counts = diabetes[col].value_counts(dropna = False)\n",
    "    print(f\"Single value entry in column {col} :  {value_counts[value_counts == 1].index[0]}\")\n",
    "    #print(f\"Distribution \\n{value_counts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns `metformin-pioglitazone`, `glimepiride-pioglitazone`, and `acetohexamide` show extreme imbalance in their distributions, with only one non-\"No\" entry each. Remove from the original dataframe due to their lack of significant variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter from matching_rows_df those only they have 1 Steady instances\n",
    "steadys = [\"metformin-pioglitazone\",\"glimepiride-pioglitazone\",\"acetohexamide\"] \n",
    "val =\"Steady\"\n",
    "\n",
    "# Filter rows where exactly one of the specified columns has the value 'Steady'\n",
    "filtered_df = diabetes.loc[\n",
    "    (diabetes[steadys[0]] == val).astype(int) +\n",
    "    (diabetes[steadys[1]] == val).astype(int) +\n",
    "    (diabetes[steadys[2]] == val).astype(int) == 1\n",
    "]\n",
    "\n",
    "# Remove rows and columns as they do not have variability after removing\n",
    "print(f\"Actual dimension: {diabetes.shape}\")\n",
    "print(f\"Removing rows: {filtered_df.index}\")\n",
    "diabetes = diabetes.drop(filtered_df.index)\n",
    "print(f\"After dimension: {diabetes.shape}\")\n",
    "print(\"Checking column variability\")\n",
    "cols_without_variability = columns_without_variability(diabetes)\n",
    "print(f\"Removing columns: {cols_without_variability}\")\n",
    "diabetes = diabetes.drop(columns = cols_without_variability)\n",
    "print(f\"Later dimension: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check `admission_source_id:13` and `payer_code:FR` cases to determine their actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove single 2 rows \n",
    "print(f\"Actual dimension: {diabetes.shape}\")\n",
    "print(f\"Removing {len(diabetes[(diabetes['admission_source_id'] == 13) ^ (diabetes['payer_code'] == 'FR')])} rows.\")\n",
    "diabetes = diabetes.drop(diabetes[(diabetes[\"admission_source_id\"] == 13) ^ (diabetes[\"payer_code\"] == \"FR\")].index)\n",
    "print(f\"After dimension: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check dtype uniformity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "print(f\"\\nData information: {diabetes.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical data comprobations\n",
    "num_cols = diabetes.select_dtypes(include='int64')\n",
    "\n",
    "# Check column values, correspond to dtypes\n",
    "for cat in num_cols.columns:\n",
    "    print(f\"\\nColumn: {cat} values: {diabetes[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change admission_type_id, discharge_disposition_id  &  admission_source_id  to categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admission_type_id, discharge_disposition_id  &  admission_source_id  are categorical no numericals. Change\n",
    "cols_to_change = [\"admission_type_id\",\"discharge_disposition_id\", \"admission_source_id\"]\n",
    "diabetes[cols_to_change] =  diabetes[cols_to_change].astype(object)\n",
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get updated list\n",
    "num_cols = diabetes.select_dtypes(include='int64')\n",
    "\n",
    "# Check column values, correspond to dtypes\n",
    "for cat in num_cols.columns:\n",
    "    print(f\"\\nColumn: {cat} values: {diabetes[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize memory use changing object to string\n",
    "categorical_cols = diabetes.select_dtypes('object').columns.tolist()\n",
    "\n",
    "# Check column values, correspond to dtypes\n",
    "for cat in categorical_cols:\n",
    "    print(f\"\\nColumn: {cat} values: {diabetes[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# get categorical column pairs\n",
    "categorical_col_pair = list(itertools.combinations(categorical_cols, 2))       \n",
    "\n",
    "# visualize data relations\n",
    "for pair in categorical_col_pair:\n",
    "    print(f\"\\n{pair[0]} distribution per {pair[1]}\")\n",
    "    print(f\"{diabetes.groupby(pair[0])[pair[1]].value_counts(dropna= False).unstack().fillna(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create folder\n",
    "tmp_folder = \"./tmp_folder\"\n",
    "os.mkdir(tmp_folder)\n",
    "\n",
    "# save data\n",
    "diabetes.to_parquet(os.path.join(tmp_folder,\"refined_file.parquet\"),engine=\"pyarrow\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORRECT INBALANCES\n",
    "\n",
    "Examine the data distribution for potential imbalances, which will help determine the appropriate corrective actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_imbalanced_columns(data, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Detect columns with imbalanced classes based on the given threshold.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame to check for imbalanced columns.\n",
    "        threshold (float): The proportion threshold to detect imbalance. \n",
    "                           Default is 0.1 (10%). A class is considered imbalanced\n",
    "                           if its proportion is below this threshold or above 1 - threshold.\n",
    "                           \n",
    "    Returns:\n",
    "        imbalanced_cols (list): List of column names with imbalanced data.\n",
    "    \"\"\"\n",
    "    imbalanced_cols = []\n",
    "    \n",
    "    for col in data.columns:\n",
    "        value_counts = data[col].value_counts(normalize=True, dropna=False)     \n",
    "        \n",
    "        # Check if any class proportion is below the threshold or above (1 - threshold)\n",
    "        if any((value_counts < threshold) | (value_counts > (1 - threshold))):\n",
    "            imbalanced_cols.append(col)\n",
    "    \n",
    "    return imbalanced_cols\n",
    "\n",
    "def show_values_proportions(df, col):\n",
    "    \"\"\"\n",
    "    Create dataframe that helps to visualize value_counts and data proportion\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to filter data\n",
    "        col (str): column to filter\n",
    "                           \n",
    "    Returns:\n",
    "        null\n",
    "    \"\"\"\n",
    "     \n",
    "    # Combine proportions into a DataFrame for easy comparison\n",
    "    data =  pd.DataFrame({\n",
    "        'Values': df[col].value_counts(dropna=False),\n",
    "        'Proportions': df[col].value_counts(normalize = True, dropna=False)\n",
    "    }).fillna(0)\n",
    "\n",
    "    # print data\n",
    "    print(data)\n",
    "\n",
    "# recover again data\n",
    "diabetes = pd.read_parquet(os.path.join(tmp_folder,\"refined_file.parquet\"),engine=\"pyarrow\")\n",
    "\n",
    "# find invalances and print results\n",
    "imbalanced_columns = detect_imbalanced_columns(diabetes, threshold= 0.1)\n",
    "if imbalanced_columns:\n",
    "    print(f\"From: {len(diabetes.columns)} inbalance are: {len(imbalanced_columns)}\")\n",
    "    print(f\"Imbalanced columns:{imbalanced_columns}\")\n",
    "    for col in imbalanced_columns:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        # print values\n",
    "        show_values_proportions(diabetes, col)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerical columns such as \"number_emergency\", \"num_procedures\", \"number_inpatient\", and \"number_outpatient\" show a large number of instances with no visits, while the rest are spread across their respective values. Generalizing them into 2 groups (whether there have been emergency visits or not) seems like a good action.\n",
    "\n",
    "Similarly, the generalization or grouping of other variables such as \"time_in_hospital\", \"age\", \"readmitted\", and \"number_diagnoses\" can help better balance the proportions of the data.\n",
    "\n",
    "### Data Generalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy original data to manipulate\n",
    "df1  = diabetes.copy()\n",
    "\n",
    "# COLUMN: \"readmitted\" \n",
    "col = \"readmitted\"\n",
    "df1.loc[df1[col] != \"NO\", col] = \"Yes\"\n",
    "df1.loc[df1[col] == \"NO\", col] = \"No\"\n",
    "\n",
    "# visualize changes\n",
    "print(\"Real:\")\n",
    "show_values_proportions(diabetes,col)\n",
    "print(\"\\nNew:\")\n",
    "show_values_proportions(df1,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COLUMN: \"age\" \n",
    "GENERALIZE TO\n",
    "[0-20) == [0-10) & [10-20)\n",
    "[20-40) == [20-30) & [30-40)\n",
    "[40-60) == [40-50) & [50-60)\n",
    "[60-80) == [60-70) & [70-80)\n",
    "[80-100) == [80-90) & [90-100)\n",
    "\"\"\"\n",
    "col = \"age\"\n",
    "df1.loc[(df1[col] == \"[0-10)\") | (df1[col] == \"[10-20)\"),col] = \"[0-20)\"\n",
    "df1.loc[(df1[col] == \"[20-30)\") | (df1[col] == \"[30-40)\"),col]= \"[20-40)\"\n",
    "df1.loc[(df1[col] == \"[40-50)\") | (df1[col] == \"[50-60)\"),col] = \"[40-60)\"\n",
    "df1.loc[(df1[col] == \"[60-70)\") | (df1[col] == \"[70-80)\"),col] = \"[60-80)\"\n",
    "df1.loc[(df1[col] == \"[80-90)\") | (df1[col] == \"[90-100)\"),col] = \"[80-100)\"\n",
    "\n",
    "# visualize changes\n",
    "print(\"Real:\")\n",
    "show_values_proportions(diabetes,col)\n",
    "print(\"\\nNew:\")\n",
    "show_values_proportions(df1,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COLUMN: time_in_hospital\n",
    "GENERALIZE INTO 4 GROUPS\n",
    "\"\"\"\n",
    "col = \"time_in_hospital\"\n",
    "df1.loc[(df1[col] == 1) | (df1[col] == 2) | (df1[col] == 3) | (df1[col] == 4) ,col] = \"[1-4]\"\n",
    "df1.loc[(df1[col] == 5) | (df1[col] == 6) |  (df1[col] == 7) | (df1[col] == 8) ,col] = \"[5-8]\"\n",
    "df1.loc[(df1[col] == 9) | (df1[col] == 10) | (df1[col] == 11) | (df1[col] == 12) ,col] = \"[9-12]\"\n",
    "df1.loc[(df1[col] == 13) | (df1[col] == 14) | (df1[col] == 15) | (df1[col] == 16) ,col] = \"[13-16]\"\n",
    "\n",
    "# visualize changes\n",
    "print(\"Real:\")\n",
    "show_values_proportions(diabetes,col)\n",
    "print(\"\\nNew:\")\n",
    "show_values_proportions(df1,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize number_outpatient in two groups\n",
    "col = \"number_outpatient\"\n",
    "col1 = \"outpatient\"\n",
    "df1.loc[df1[col] != 0, col1] = \"Yes\"\n",
    "df1.loc[df1[col] == 0, col1] = \"No\"\n",
    "\n",
    "# visualize changes\n",
    "print(\"Real:\")\n",
    "show_values_proportions(diabetes,col)\n",
    "print(\"\\nNew:\")\n",
    "show_values_proportions(df1,col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize number_impatient in two groups\n",
    "col = \"number_inpatient\"\n",
    "col1 = \"inpatient\"\n",
    "df1.loc[df1[col] != 0, col1] = \"Yes\"\n",
    "df1.loc[df1[col] == 0, col1] = \"No\"\n",
    "\n",
    "# visualize changes\n",
    "print(\"Real:\")\n",
    "show_values_proportions(diabetes,col)\n",
    "print(\"\\nNew:\")\n",
    "show_values_proportions(df1,col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize num_procedures in two groups\n",
    "col = \"num_procedures\"\n",
    "col1 = \"procedures\"\n",
    "df1.loc[df1[col] != 0, col1] = \"Yes\"\n",
    "df1.loc[df1[col] == 0, col1] = \"No\"\n",
    "\n",
    "# visualize changes\n",
    "print(\"Real:\")\n",
    "show_values_proportions(diabetes,col)\n",
    "print(\"\\nNew:\")\n",
    "show_values_proportions(df1,col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize number_emergency in two groups\n",
    "col = \"number_emergency\"\n",
    "col1 = \"emergencies\"\n",
    "df1.loc[df1[col] != 0, col1] = \"Yes\"\n",
    "df1.loc[df1[col] == 0, col1] = \"No\"\n",
    "\n",
    "# visualize changes\n",
    "print(\"Real:\")\n",
    "show_values_proportions(diabetes,col)\n",
    "print(\"\\nNew:\")\n",
    "show_values_proportions(df1,col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize number_emergency in two groups\n",
    "col = \"number_diagnoses\"\n",
    "df1.loc[(df1[col] == 1) | (df1[col] == 2) | (df1[col] == 3) | (df1[col] == 4) |\n",
    "        (df1[col] == 5) | (df1[col] == 6)  | (df1[col] == 7) | (df1[col] == 8),col] = \"[0-8]\"\n",
    "df1.loc[(df1[col] == 9) | (df1[col] == 10) | (df1[col] == 11) | (df1[col] == 12) |\n",
    "        (df1[col] == 13) | (df1[col] == 14)  | (df1[col] == 15) | (df1[col] == 16),col] = \"[9-16]\"\n",
    "\n",
    "# visualize changes\n",
    "print(\"Real:\")\n",
    "show_values_proportions(diabetes,col)\n",
    "print(\"\\nNew:\")\n",
    "show_values_proportions(df1,col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original columns \n",
    "col_list = [\"number_emergency\",\"num_procedures\",\"number_inpatient\",\n",
    "            \"number_outpatient\",\"time_in_hospital\", \"age\",\"readmitted\",\"number_diagnoses\"]\n",
    "\n",
    "print(f\"Column length after: {len(df1.columns)} to eliminate: {len(col_list)}\")\n",
    "df1 = df1.drop(col_list, axis=1)\n",
    "print(f\"Column length now: {len(df1.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save generalized data\n",
    "df1.to_parquet(os.path.join(tmp_folder,\"generalized_file.parquet\"),engine=\"pyarrow\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance data distribution\n",
    "\n",
    "Race, admission_type_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE SYNTHETIZER & SYNTHETIC DATA WITH SDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataframe into`SingleTableMetadata` data type \n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "def create_and_modify_metadata(df):\n",
    "    \"\"\"\n",
    "    SingleTableMetadata type data creation. Obtains information directly from original dataframe and\n",
    "    adjust dtype for \"_id\" type columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        SingleTableMetadata: metadata to create synthetic data\n",
    "    \"\"\"\n",
    "    # Automatically detect metadata from the actual DataFrame\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(df)\n",
    "\n",
    "    # Change dtype of \"_id\" columns. Threat as categorical instead of numerical\n",
    "    for column_name in metadata.columns:\n",
    "        if '_id' in column_name:\n",
    "            metadata.update_column(column_name, sdtype='categorical')\n",
    "    return metadata\n",
    "\n",
    "# create metadata\n",
    "# recover refined or preprocessed file\n",
    "diabetes = pd.read_parquet(\"./refined_file.parquet\",engine=\"pyarrow\")\n",
    "metadata = create_and_modify_metadata(diabetes)\n",
    "\n",
    "# Check if metadata has been correctly generated\n",
    "print(metadata)\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "\n",
    "# Create synthetizer and synthetic data \n",
    "def synthetic_data_creation(md, df):\n",
    "    \"\"\"\n",
    "    Creates synthetizer, trains synthetizer with real data and creates new \n",
    "    synthetic data.\n",
    "    \n",
    "    Parameters:\n",
    "        md (SingleTableMetadata): Metadata of DataFrame.\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        SingleTableMetadata: metadata to create synthetic data\n",
    "    \"\"\"\n",
    "\n",
    "    # create synthetizer\n",
    "    synthesizer = GaussianCopulaSynthesizer(\n",
    "        md,\n",
    "        enforce_min_max_values=True,\n",
    "        enforce_rounding=True) \n",
    "\n",
    "    # train data to learn from real data\n",
    "    synthesizer.fit(\n",
    "        data = df\n",
    "    )\n",
    "\n",
    "    # create new data (same dimensions) based on learned model\n",
    "    synthetic_data = synthesizer.sample(\n",
    "        num_rows=df.shape[0]\n",
    "    )\n",
    "    return synthetic_data\n",
    "\n",
    "# obtain synthetic data\n",
    "synthetic_data = synthetic_data_creation(metadata, diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE SYNTHETIC DATA AND VALIDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Real dimension: {diabetes.shape}\")\n",
    "print(f\"Synth dimension: {synthetic_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information from both datasets\n",
    "real_data_info = pd.DataFrame({\n",
    "    'Column': diabetes.columns,\n",
    "    'Real Non-Null Count':diabetes.notnull().sum()\n",
    "})\n",
    "\n",
    "# For synthetic data\n",
    "synthetic_data_info = pd.DataFrame({\n",
    "    'Column': synthetic_data.columns,\n",
    "    'Synthetic Non-Null Count':synthetic_data.notnull().sum()\n",
    "})\n",
    "\n",
    "# Merge the two DataFrames on the 'Column' name\n",
    "comparison = pd.merge(real_data_info, synthetic_data_info, on='Column', how='outer')\n",
    "\n",
    "# Print comparison table\n",
    "print(\"Comparison of Real and Synthetic Data:\")\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Major Differences and Improve the Model\n",
    "\n",
    "Analyze proportional differences and visualize them graphically for better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_proportion_diffs(real, other, col, text):\n",
    "    \"\"\"\n",
    "    Creates real and adjusted proportions values to compare\n",
    "    \n",
    "    Parameters:\n",
    "        real (pd.DataFrame): The original DataFrame.\n",
    "        other (pd.DataFrame): Dataframe to compare with original DataFrame\n",
    "        col (str): The column to apply the comparison\n",
    "        text (str): Text to apply comparison dataframe for comparative Dataframe\n",
    "\n",
    "    Returns:       \n",
    "        comparison_df pd.DataFrame: Dataframe that comparates real and other dataframes proportions\n",
    "    \"\"\"\n",
    "    # Compute proportions for real and adjusted data\n",
    "    real_proportions = real[col].value_counts(normalize=True).sort_index()\n",
    "    other_proportions = other[col].value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    # Combine proportions into a DataFrame for easy comparison\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Real': real_proportions,\n",
    "         text: other_proportions\n",
    "    }).fillna(0)\n",
    "\n",
    "    # Calculate differences\n",
    "    comparison_df['Absolute_Difference'] = comparison_df['Real'] - comparison_df[text]\n",
    "    comparison_df['Relative_Difference'] = comparison_df['Absolute_Difference'] / comparison_df['Real'].replace(0, 1)  # Avoid division by zero\n",
    "\n",
    "    return comparison_df\n",
    "\n",
    "# Create and visualize data proportion\n",
    "for col in diabetes.columns:\n",
    "    print(f\"\\n Proportion differences for column '{col}':\") \n",
    "    comparison_df= check_proportion_diffs(diabetes, synthetic_data, col, \"Synthetic\")\n",
    "    print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_distributions(comparison_df, col, text):\n",
    "    \"\"\"\n",
    "    Compare the distributions of a specific column in the real and adjusted DataFrames with visualizations.\n",
    "    \n",
    "    Parameters:\n",
    "        comparison_df (pd.DataFrame): The DataFrame with proportion comparation between real and adjusted data.\n",
    "        col (str): The column name to compare.\n",
    "        text (str): Text to refer column that correspond to comparative data\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    comparison_df.plot(kind='bar', width=0.8)\n",
    "    plt.title(f\"Comparison of Proportions for '{col}'\")\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(['Real',text])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Visualize comparison_df data\n",
    "for col in diabetes.columns:\n",
    "    print(f\"\\nColumn: {col}\")    \n",
    "    comparison_df= check_proportion_diffs(diabetes, synthetic_data, col, \"Synthetic\")\n",
    "    compare_distributions(comparison_df[[\"Real\",\"Synthetic\"]], col, \"Synthetic\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CORRELATION MATRIX\n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "corr_r = diabetes.corr()\n",
    "corr_s = synthetic_data.corr()\n",
    "sns.heatmap(corr_r, \n",
    "            xticklabels=corr_r.columns.values,\n",
    "            yticklabels=corr_r.columns.values,\n",
    "            cmap=\"Blues\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[0])\n",
    "sns.heatmap(corr_s, \n",
    "            xticklabels=corr_s.columns.values,\n",
    "            yticklabels=corr_s.columns.values,\n",
    "            cmap=\"Greens\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[1])\n",
    "ax[0].set_title(\"REAL\")\n",
    "ax[1].set_title(\"SYNTH\")\n",
    "plt.tight_layout()     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADJUST REAL DATA\n",
    "\n",
    "Adjust the frequencies of categories in the real data to match the desired proportions. This may involve oversampling underrepresented categories or undersampling overrepresented ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def adjust_data_distribution(df, col):\n",
    "    \"\"\"\n",
    "    Adjust the distribution of a specific column in the DataFrame to match its real proportions.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        col (str): The column name to adjust.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with adjusted distribution for the specified column.\n",
    "    \"\"\"\n",
    "    real_proportions = df[col].value_counts(normalize=True)\n",
    "    adjusted_real_df = pd.DataFrame()\n",
    "    \n",
    "    for value, proportion in real_proportions.items():\n",
    "        current_count = df[df[col] == value].shape[0]\n",
    "        target_count = int(proportion * len(df))\n",
    "        \n",
    "        if target_count > current_count:\n",
    "            # Oversample\n",
    "            sample_df = df[df[col] == value]\n",
    "            sampled_df = resample(sample_df, replace=True, n_samples=target_count - current_count)\n",
    "            adjusted_real_df = pd.concat([adjusted_real_df, sample_df, sampled_df])\n",
    "        elif target_count < current_count:\n",
    "            # Undersample\n",
    "            sampled_df = resample(df[df[col] == value], replace=False, n_samples=target_count)\n",
    "            adjusted_real_df = pd.concat([adjusted_real_df, sampled_df])\n",
    "        else:\n",
    "            # No adjustment\n",
    "            adjusted_real_df = pd.concat([adjusted_real_df, df[df[col] == value]])\n",
    "    \n",
    "    return adjusted_real_df\n",
    "\n",
    "\n",
    "# Visualize adjusted data distribution \n",
    "for col in diabetes.columns:   \n",
    "    # Adjust the real data\n",
    "    adjusted_real_df = adjust_data_distribution(diabetes, col)\n",
    "    \n",
    "    # Comparate \n",
    "    comparison_df= check_proportion_diffs(diabetes, adjusted_real_df, col, \"Adjusted_real\")\n",
    "    compare_distributions(comparison_df[[\"Real\",\"Adjusted_real\"]], col, \"Adjusted_real\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Column:{col}\n",
      "Caucasian          76099\n",
      "AfricanAmerican    19210\n",
      "Other               3776\n",
      "Hispanic            2037\n",
      "Asian                641\n",
      "Name: race, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "Female    54708\n",
      "Male      47055\n",
      "Name: gender, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "[70-80)     26066\n",
      "[60-70)     22482\n",
      "[50-60)     17256\n",
      "[80-90)     17197\n",
      "[40-50)      9685\n",
      "[30-40)      3775\n",
      "[90-100)     2793\n",
      "[20-30)      1657\n",
      "[10-20)       691\n",
      "[0-10)        161\n",
      "Name: age, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "1    53988\n",
      "3    18868\n",
      "2    18480\n",
      "6     5291\n",
      "5     4785\n",
      "8      320\n",
      "7       21\n",
      "4       10\n",
      "Name: admission_type_id, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "1     60232\n",
      "3     13954\n",
      "6     12902\n",
      "18     3691\n",
      "2      2128\n",
      "22     1992\n",
      "11     1642\n",
      "5      1184\n",
      "25      989\n",
      "4       815\n",
      "7       623\n",
      "23      412\n",
      "13      399\n",
      "14      372\n",
      "28      139\n",
      "8       108\n",
      "15       63\n",
      "24       48\n",
      "9        21\n",
      "17       14\n",
      "16       11\n",
      "19        8\n",
      "10        6\n",
      "27        5\n",
      "12        3\n",
      "20        2\n",
      "Name: discharge_disposition_id, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "7     57492\n",
      "1     29564\n",
      "17     6781\n",
      "4      3187\n",
      "6      2264\n",
      "2      1104\n",
      "5       855\n",
      "3       187\n",
      "20      161\n",
      "9       125\n",
      "8        16\n",
      "22       12\n",
      "10        8\n",
      "14        2\n",
      "11        2\n",
      "25        2\n",
      "13        1\n",
      "Name: admission_source_id, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "3     17756\n",
      "2     17224\n",
      "1     14206\n",
      "4     13924\n",
      "5      9966\n",
      "6      7539\n",
      "7      5859\n",
      "8      4390\n",
      "9      3002\n",
      "10     2342\n",
      "11     1855\n",
      "12     1448\n",
      "13     1210\n",
      "14     1042\n",
      "Name: time_in_hospital, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "NaN    40255\n",
      "MC     32439\n",
      "HM      6274\n",
      "SP      5007\n",
      "BC      4655\n",
      "MD      3532\n",
      "CP      2531\n",
      "UN      2448\n",
      "CM      1937\n",
      "OG      1033\n",
      "PO       592\n",
      "DM       549\n",
      "CH       146\n",
      "WC       135\n",
      "OT        95\n",
      "MP        79\n",
      "SI        55\n",
      "FR         1\n",
      "Name: payer_code, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "NaN                              49947\n",
      "InternalMedicine                 14635\n",
      "Emergency/Trauma                  7565\n",
      "Family/GeneralPractice            7440\n",
      "Cardiology                        5351\n",
      "                                 ...  \n",
      "SportsMedicine                       1\n",
      "Speech                               1\n",
      "Perinatology                         1\n",
      "Neurophysiology                      1\n",
      "Pediatrics-InfectiousDiseases        1\n",
      "Name: medical_specialty, Length: 73, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "1      3208\n",
      "43     2804\n",
      "44     2496\n",
      "45     2376\n",
      "38     2212\n",
      "       ... \n",
      "120       1\n",
      "132       1\n",
      "121       1\n",
      "126       1\n",
      "118       1\n",
      "Name: num_lab_procedures, Length: 118, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "0    46652\n",
      "1    20741\n",
      "2    12716\n",
      "3     9443\n",
      "6     4954\n",
      "4     4180\n",
      "5     3077\n",
      "Name: num_procedures, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "13    6086\n",
      "12    6004\n",
      "11    5795\n",
      "15    5792\n",
      "14    5707\n",
      "      ... \n",
      "70       2\n",
      "75       2\n",
      "81       1\n",
      "79       1\n",
      "74       1\n",
      "Name: num_medications, Length: 75, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "0     85024\n",
      "1      8547\n",
      "2      3594\n",
      "3      2042\n",
      "4      1099\n",
      "5       533\n",
      "6       303\n",
      "7       155\n",
      "8        98\n",
      "9        83\n",
      "10       57\n",
      "11       42\n",
      "13       31\n",
      "12       30\n",
      "14       28\n",
      "15       20\n",
      "16       15\n",
      "17        8\n",
      "21        7\n",
      "20        7\n",
      "18        5\n",
      "22        5\n",
      "19        3\n",
      "27        3\n",
      "24        3\n",
      "26        2\n",
      "23        2\n",
      "25        2\n",
      "33        2\n",
      "35        2\n",
      "36        2\n",
      "29        2\n",
      "34        1\n",
      "39        1\n",
      "42        1\n",
      "28        1\n",
      "37        1\n",
      "38        1\n",
      "40        1\n",
      "Name: number_outpatient, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "0     90380\n",
      "1      7677\n",
      "2      2042\n",
      "3       725\n",
      "4       374\n",
      "5       192\n",
      "6        94\n",
      "7        73\n",
      "8        50\n",
      "10       34\n",
      "9        33\n",
      "11       23\n",
      "13       12\n",
      "12       10\n",
      "22        6\n",
      "16        5\n",
      "18        5\n",
      "19        4\n",
      "20        4\n",
      "15        3\n",
      "14        3\n",
      "25        2\n",
      "21        2\n",
      "28        1\n",
      "42        1\n",
      "46        1\n",
      "76        1\n",
      "37        1\n",
      "64        1\n",
      "63        1\n",
      "54        1\n",
      "24        1\n",
      "29        1\n",
      "Name: number_emergency, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "0     67627\n",
      "1     19521\n",
      "2      7566\n",
      "3      3411\n",
      "4      1622\n",
      "5       812\n",
      "6       480\n",
      "7       268\n",
      "8       151\n",
      "9       111\n",
      "10       61\n",
      "11       49\n",
      "12       34\n",
      "13       20\n",
      "14       10\n",
      "15        9\n",
      "16        6\n",
      "19        2\n",
      "17        1\n",
      "21        1\n",
      "18        1\n",
      "Name: number_inpatient, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "428    6862\n",
      "414    6580\n",
      "786    4016\n",
      "410    3614\n",
      "486    3508\n",
      "       ... \n",
      "373       1\n",
      "314       1\n",
      "684       1\n",
      "217       1\n",
      "V51       1\n",
      "Name: diag_1, Length: 717, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "276     6752\n",
      "428     6662\n",
      "250     6071\n",
      "427     5036\n",
      "401     3736\n",
      "        ... \n",
      "E918       1\n",
      "46         1\n",
      "V13        1\n",
      "E850       1\n",
      "927        1\n",
      "Name: diag_2, Length: 749, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "250     11555\n",
      "401      8288\n",
      "276      5175\n",
      "428      4577\n",
      "427      3955\n",
      "        ...  \n",
      "657         1\n",
      "684         1\n",
      "603         1\n",
      "E826        1\n",
      "971         1\n",
      "Name: diag_3, Length: 790, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "9     49473\n",
      "5     11392\n",
      "8     10616\n",
      "7     10393\n",
      "6     10161\n",
      "4      5536\n",
      "3      2835\n",
      "2      1023\n",
      "1       219\n",
      "16       45\n",
      "10       17\n",
      "13       16\n",
      "11       11\n",
      "15       10\n",
      "12        9\n",
      "14        7\n",
      "Name: number_diagnoses, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "None    96417\n",
      "Norm     2597\n",
      ">200     1485\n",
      ">300     1264\n",
      "Name: max_glu_serum, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "None    84745\n",
      ">8       8216\n",
      "Norm     4990\n",
      ">7       3812\n",
      "Name: A1Cresult, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        81776\n",
      "Steady    18345\n",
      "Up         1067\n",
      "Down        575\n",
      "Name: metformin, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        100224\n",
      "Steady      1384\n",
      "Up           110\n",
      "Down          45\n",
      "Name: repaglinide, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101060\n",
      "Steady       668\n",
      "Up            24\n",
      "Down          11\n",
      "Name: nateglinide, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101677\n",
      "Steady        79\n",
      "Up             6\n",
      "Down           1\n",
      "Name: chlorpropamide, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        96572\n",
      "Steady     4670\n",
      "Up          327\n",
      "Down        194\n",
      "Name: glimepiride, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101762\n",
      "Steady         1\n",
      "Name: acetohexamide, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        89078\n",
      "Steady    11355\n",
      "Up          770\n",
      "Down        560\n",
      "Name: glipizide, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        91113\n",
      "Steady     9274\n",
      "Up          812\n",
      "Down        564\n",
      "Name: glyburide, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101740\n",
      "Steady        23\n",
      "Name: tolbutamide, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        94436\n",
      "Steady     6975\n",
      "Up          234\n",
      "Down        118\n",
      "Name: pioglitazone, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        95399\n",
      "Steady     6099\n",
      "Up          178\n",
      "Down         87\n",
      "Name: rosiglitazone, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101455\n",
      "Steady       295\n",
      "Up            10\n",
      "Down           3\n",
      "Name: acarbose, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101725\n",
      "Steady        31\n",
      "Down           5\n",
      "Up             2\n",
      "Name: miglitol, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101760\n",
      "Steady         3\n",
      "Name: troglitazone, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101724\n",
      "Steady        38\n",
      "Up             1\n",
      "Name: tolazamide, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        47380\n",
      "Steady    30849\n",
      "Down      12218\n",
      "Up        11316\n",
      "Name: insulin, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101057\n",
      "Steady       692\n",
      "Up             8\n",
      "Down           6\n",
      "Name: glyburide-metformin, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101750\n",
      "Steady        13\n",
      "Name: glipizide-metformin, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101762\n",
      "Steady         1\n",
      "Name: glimepiride-pioglitazone, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101761\n",
      "Steady         2\n",
      "Name: metformin-rosiglitazone, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No        101762\n",
      "Steady         1\n",
      "Name: metformin-pioglitazone, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "No    54754\n",
      "Ch    47009\n",
      "Name: change, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "Yes    78361\n",
      "No     23402\n",
      "Name: diabetesMed, dtype: int64\n",
      "\n",
      " Column:{col}\n",
      "NO     54861\n",
      ">30    35545\n",
      "<30    11357\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in diabetes.columns:\n",
    "    print(\"\\n Column:{col}\")\n",
    "    print(diabetes[col].value_counts(dropna =False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "adjusted_real_df.to_parquet(\"./adjusted.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RE-CREATE SYNTH DATA AND VALIDATE PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO METADATA funtzioari deitu konpondutako dataset-akin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SYNTH SORRERA funtzioari deitu konpondutako dataset-akin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
