{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDV SYNTHETIC DATA GENERATION\n",
    "\n",
    "## LOAD PREPROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# create folder\n",
    "tmp_folder = \"../resources\"\n",
    "diabetes = pd.read_parquet(os.path.join(tmp_folder,\"preprocessed_file.parquet\"),engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataframe into`SingleTableMetadata` data type \n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "def create_metadata(df):\n",
    "    \"\"\"\n",
    "    SingleTableMetadata type data creation. Obtains information directly from original dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        SingleTableMetadata: metadata to create synthetic data\n",
    "    \"\"\"\n",
    "    # Automatically detect metadata from the actual DataFrame\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(df)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# create metadata\n",
    "metadata = create_metadata(diabetes)\n",
    "\n",
    "# Check if metadata has been correctly generated\n",
    "print(metadata)\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET SYNTHETIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import CTGANSynthesizer\n",
    "\n",
    "def create_synthesizer (df, md):\n",
    "    \"\"\"\n",
    "    Creates synthetizer, trains synthesizer with real data and creates new \n",
    "    synthetic data.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        md (SingleTableMetadata): Metadata of DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        sinthetizer (CTGANSynthesizer): returns trained synthesizer.\n",
    "    \"\"\"\n",
    "\n",
    "    # create synthesizer\n",
    "    synthesizer = CTGANSynthesizer(\n",
    "        md, # required\n",
    "        enforce_rounding=True,\n",
    "        epochs=100,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # train data to learn from real data\n",
    "    synthesizer.fit(\n",
    "        data = df\n",
    "    )\n",
    "\n",
    "    return synthesizer    \n",
    "\n",
    "# call to function\n",
    "synthesizer = create_synthesizer (diabetes, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data with synthesizer\n",
    "def create_synth_data (df, synth):\n",
    "    \"\"\"\n",
    "    Creates synthetic data using metadata and specific numerical distribution\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        synth (GaussianCopulaSynthesizer): trained synthesizer.\n",
    "\n",
    "    Returns:\n",
    "        synthetic_data (pd.DataFrame): new synthetic data.\n",
    "    \"\"\"   \n",
    "    # create new synth data\n",
    "    synthetic_data = synth.sample(\n",
    "        num_rows=df.shape[0]\n",
    "    )\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "# obtain synthetic data\n",
    "synthetic_data = create_synth_data(diabetes, synthesizer)\n",
    "\n",
    "# print result\n",
    "synthetic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE THE RESULTED SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "\n",
    "quality_report = evaluate_quality(\n",
    "    diabetes,\n",
    "    synthetic_data,\n",
    "    metadata\n",
    ")\n",
    "\n",
    "print(f\"Quality of synthetic data is: {quality_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE REAL DATA WITH SYNTHETIC DATA\n",
    "\n",
    "### Compare dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Real dimension: {diabetes.shape}\")\n",
    "print(f\"Synth dimension: {synthetic_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare general data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information from both datasets\n",
    "real_data_info = pd.DataFrame({\n",
    "    'Column': diabetes.columns,\n",
    "    'Real Non-Null Count':diabetes.notnull().sum()\n",
    "})\n",
    "\n",
    "# For synthetic data\n",
    "synthetic_data_info = pd.DataFrame({\n",
    "    'Column': synthetic_data.columns,\n",
    "    'Synthetic Non-Null Count':synthetic_data.notnull().sum()\n",
    "})\n",
    "\n",
    "# Merge the two DataFrames on the 'Column' name\n",
    "comparison = pd.merge(real_data_info, synthetic_data_info, on='Column', how='outer')\n",
    "\n",
    "# Print comparison table\n",
    "print(\"Comparison of Real and Synthetic Data:\")\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data anonymization\n",
    "\n",
    "Check first N rows and their sensible columns values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect sensible columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify identity sensible data: \n",
    "sensitive_columns = ['race', 'gender', 'age', 'admission_type_id','discharge_disposition_id','admission_source_id','payer_code']\n",
    "print(f\"\\nSensitive columns: {sensitive_columns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sensible data anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Real: {diabetes[sensitive_columns].head()}\")\n",
    "print(f\"\\nSynthetic: {synthetic_data[sensitive_columns].head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for numeric data correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CORRELATION MATRIX\n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "corr_r = diabetes.corr()\n",
    "corr_s = synthetic_data.corr()\n",
    "sns.heatmap(corr_r, \n",
    "            xticklabels=corr_r.columns.values,\n",
    "            yticklabels=corr_r.columns.values,\n",
    "            cmap=\"Blues\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[0])\n",
    "sns.heatmap(corr_s, \n",
    "            xticklabels=corr_s.columns.values,\n",
    "            yticklabels=corr_s.columns.values,\n",
    "            cmap=\"Greens\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[1])\n",
    "ax[0].set_title(\"REAL\")\n",
    "ax[1].set_title(\"SYNTH\")\n",
    "plt.tight_layout()     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save synthetic data\n",
    "synthetic_data.to_parquet(os.path.join(tmp_folder,\"synthetic_data.parquet\"),engine=\"pyarrow\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save synthetizer:\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(\"../resources\",\"synthesizer.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(synthesizer, file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
