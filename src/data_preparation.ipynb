{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION\n",
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "'''# metadata \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.variables) '''\n",
    "  \n",
    "# fetch dataset \n",
    "diabetes_130_us_hospitals_for_years_1999_2008 = fetch_ucirepo(id=296) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = diabetes_130_us_hospitals_for_years_1999_2008.data.features \n",
    "y = diabetes_130_us_hospitals_for_years_1999_2008.data.targets \n",
    "\n",
    "# create complete real_data\n",
    "diabetes = pd.DataFrame(X)\n",
    "diabetes[\"readmitted\"] = y\n",
    "\n",
    "# visualize data\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE & PREPROCESS DATA\n",
    "\n",
    "### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Dimension: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check columns values & distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE COLUMN: check columns values & distribution\n",
    "def visualize_columns_distributions(df):\n",
    "    for col in df.columns:\n",
    "        print(f\"\\n\\nColumn: {col}\")\n",
    "\n",
    "        # Combine proportions into a DataFrame for easy comparison\n",
    "        data =  pd.DataFrame({\n",
    "            'Values': df[col].value_counts(dropna=False),\n",
    "            'Proportions': df[col].value_counts(normalize = True, dropna=False)\n",
    "        }).fillna(0)\n",
    "\n",
    "        # print data\n",
    "        print(data)\n",
    "    \n",
    "# call to columns_distibution function\n",
    "visualize_columns_distributions(diabetes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is not balanced they are more caucasian (%74) than any other race.\n",
    "\n",
    "###  Generalize 'Nan' race values to 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize Nan race as 'Other'\n",
    "import numpy as np\n",
    "diabetes.loc[diabetes[\"race\"].isin([np.nan ,'Other']), \"race\"] = \"Other\"\n",
    "\n",
    "# validate change\n",
    "diabetes.race.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hispanic and Asian can be generalized as other race but this way still be considerably imbalanced. \n",
    "\n",
    "###  Check 'Unknown/Invalid' gender values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Unknown/Invalid' data\n",
    "diabetes[diabetes['gender'] == 'Unknown/Invalid'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Correct 'Unknown/Invalid' gender values\n",
    "\n",
    "Only 3 registry, not possible to define gender, best option would be to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing  'Unknown/Invalid' gender data\n",
    "print(f\"Shape before drop: {diabetes.shape}\")\n",
    "diabetes = diabetes.drop(diabetes[diabetes[\"gender\"] == 'Unknown/Invalid'].index)\n",
    "\n",
    "# validating results (only 3 less)\n",
    "print(f\"Shape after drop: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check for 'missing values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls per columns (percentage)\n",
    "diabetes.isna().sum() * 100 / len(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight column has many null values (96.858387 %), best option would be to remove.\n",
    "\n",
    "####  Drop \"weight\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove weight column \n",
    "print(f\"Columns before remove {len(diabetes.columns)}\")\n",
    "diabetes = diabetes.drop('weight', axis=1)\n",
    "print(f\"Columns after remove {len(diabetes.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns `payer_code` (39.56%) and `medical_specialty` (49.08%) have many null values. Let's take actions on them.    \n",
    "\n",
    "#### Check missing value nature\n",
    "\n",
    "Are those missing values related? How they are related?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for payer_code null\n",
    "df1 = diabetes[diabetes[\"payer_code\"].isnull()]\n",
    "\n",
    "print(f\"Filtering data for `payer_code` null values new null relation is: \\n {df1.isna().sum() * 100 / len(df1)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectively great part of the missing values are related. Once `payer_code` is missing in (40%) of the cases `medical_specialty` is also missing.\n",
    "\n",
    "Check if the removing of this rows is feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data without payer code represent: {round(df1.shape[0] * 100 / diabetes.shape[0],2)} % of total data\")\n",
    "print(f\"If they are removed means reduce dimension from: {diabetes.shape[0]} lines to {diabetes.shape[0] - df1.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still enough data for synthetic data creation, so we will delete them. However, for analysis purposes, removing 40 thousand lines is not optimal at all.\n",
    "\n",
    "#### Correct missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid payer_code null data\n",
    "df1 = diabetes[~diabetes[\"payer_code\"].isnull()]\n",
    "\n",
    "# reasign again to diabetes\n",
    "diabetes = df1\n",
    "\n",
    "# validate results => no null values\n",
    "print(f\"Payer_code null values: {diabetes['payer_code'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check again null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls per columns (percentage)\n",
    "diabetes.isna().sum() * 100 / len(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove those columns that exceed 50% of the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stablish missing proportion\n",
    "missing_proportion = diabetes.isna().sum() * 100 / len(diabetes)\n",
    "\n",
    "# get columns that meet this proportion\n",
    "columns_to_drop = missing_proportion[missing_proportion > 50].index\n",
    "\n",
    "# remove columns that exceed these proportion\n",
    "print(f\"Columns: {columns_to_drop} exceed 50% of missing proportion\")\n",
    "print(f\"Actual dataframe shape: {diabetes.shape}.\\nRemoving columns that exceed the proportion.\")\n",
    "new_df = diabetes.drop(columns=columns_to_drop)\n",
    "diabetes = new_df\n",
    "print(f\"Dimension after removing data: {diabetes.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check for 'variability'\n",
    "\n",
    "Columns that have only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_without_variability(df):    \n",
    "    \"\"\"\n",
    "    Function that is responsible to determine which columnns has no variability (those which has only 1 value).    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        list(): list of variables without variability.\n",
    "    \"\"\"    \n",
    "    sobran = []\n",
    "\n",
    "    cols = df.columns\n",
    "    for col in cols:\n",
    "        if len(df[col].unique()) < 2:\n",
    "            print(f\"Column: `{col}` unique values: {df[col].unique()}\")\n",
    "            sobran.append(col)\n",
    "\n",
    "    return sobran\n",
    "\n",
    "# obtain column list without variability\n",
    "cols_without_variability = columns_without_variability(diabetes)\n",
    "\n",
    "# print result\n",
    "print(f\"Invariant columns: {cols_without_variability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns without variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns\n",
    "print(f\"Columns without variability: {cols_without_variability}\")\n",
    "print(f\"Columns before remove {len(diabetes.columns)}\")\n",
    "diabetes = diabetes.drop(columns = cols_without_variability)\n",
    "print(f\"Columns after remove {len(diabetes.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect 'sensitive columns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all columns\n",
    "print(f\"\\columns: {diabetes.columns}\\n\")\n",
    "\n",
    "# identify identity sensible data: \n",
    "sensitive_columns = ['race', 'gender', 'age', 'admission_type_id','discharge_disposition_id','admission_source_id','payer_code', 'medical_specialty']\n",
    "print(f\"\\nSensitive columns: {sensitive_columns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect 'single value entries'\n",
    "\n",
    "Columns that present a singularization risk, columns that have more than one value but only a single instance of one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_single_value_entries(df):\n",
    "    rows_to_check = []  # List to hold the rows matching the criteria\n",
    "    cols_to_check = []\n",
    "    for col in df.columns:\n",
    "        # Get the value counts for the column\n",
    "        value_counts = df[col].value_counts()\n",
    "\n",
    "        # Check if exactly one value has a count of 1\n",
    "        if (value_counts == 1).sum() == 1:\n",
    "            # Get the value that appears exactly once\n",
    "            single_value = value_counts[value_counts == 1].index[0]\n",
    "            # add column name\n",
    "            cols_to_check.append(col)\n",
    "            \n",
    "            # Select rows where this single value appears\n",
    "            matching_rows = df[df[col] == single_value]\n",
    "            \n",
    "            # Append these rows to the list\n",
    "            rows_to_check.append(matching_rows)\n",
    "\n",
    "    # Concatenate all the matching rows into a single dataframe (if needed)\n",
    "    result_df = pd.concat(rows_to_check, ignore_index=True) if rows_to_check else pd.DataFrame()\n",
    "\n",
    "    return result_df,cols_to_check\n",
    "\n",
    "# determine single value entries\n",
    "matching_rows_df, cols_to_check = determine_single_value_entries(diabetes)\n",
    "\n",
    "# check data relevancy\n",
    "for col in cols_to_check:\n",
    "    value_counts = diabetes[col].value_counts(dropna = False)\n",
    "    print(f\"Single value entry in column {col} :  {value_counts[value_counts == 1].index[0]}\")\n",
    "    #print(f\"Distribution \\n{value_counts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With synthetic data anonymization, this singularization risk can be diminished, but since there are few records, they can be analyzed to determine if they can be removed.\n",
    "\n",
    "#### Check 'single value entries'\n",
    "\n",
    "The columns `metformin-pioglitazone` and `glimepiride-pioglitazone` show a `steady` value. Do they correspond to the same individual?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter from matching_rows_df those only they have 1 Steady instances\n",
    "steadys = [\"metformin-pioglitazone\",\"glimepiride-pioglitazone\"] \n",
    "val =\"Steady\"\n",
    "\n",
    "# Filter rows where exactly one of the specified columns has the value 'Steady'\n",
    "filtered_df = diabetes.loc[\n",
    "    (diabetes[steadys[0]] == val).astype(int) +\n",
    "    (diabetes[steadys[1]] == val).astype(int) +\n",
    "    (diabetes[steadys[2]] == val).astype(int) == 1\n",
    "]\n",
    "\n",
    "# show results\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check sensitive_columns for any reidentification risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df[sensitive_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check also this columns values variability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in steadys:\n",
    "    print(f\"\\nColumn: {col} \\nunique values: {diabetes[col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two steady cases clearly pose a reidentification risk due to their singularization. If they are removed, the `metformin-pioglitazone`and `glimepiride-pioglitazone`columns will lose their variability and should also be removed.\n",
    "\n",
    "Check the other `single value entries` to evaluate if they should be removed. \n",
    "\n",
    "Check 'admission_source_id' = 13 case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk of reindetifiction better to be removed.\n",
    "diabetes[diabetes['admission_source_id'] == 13] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check 'payer_code' : 'FR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk of reindetifiction better to be removed.\n",
    "diabetes[diabetes['payer_code'] == 'FR'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate columns shape to determine if `steady` columns need to be removed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take action on 'single value entries'\n",
    "\n",
    "Remove steady rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows and columns as they do not have variability after removing\n",
    "print(f\"Actual dimension: {diabetes.shape}\")\n",
    "print(f\"Removing rows: {filtered_df.index}\")\n",
    "diabetes = diabetes.drop(filtered_df.index)\n",
    "print(f\"After dimension: {diabetes.shape}\")\n",
    "print(\"Checking column variability\")\n",
    "cols_without_variability = columns_without_variability(diabetes)\n",
    "print(f\"Removing columns: {cols_without_variability}\")\n",
    "diabetes = diabetes.drop(columns = cols_without_variability)\n",
    "print(f\"Later dimension: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the other single value registries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove single 2 rows\n",
    "print(f\"Current dimensions: {diabetes.shape}\")\n",
    "\n",
    "# Calculate how many rows will be removed\n",
    "rows_to_remove = len(diabetes[(diabetes['admission_source_id'] == 13) ^ \n",
    "                              (diabetes['payer_code'] == 'FR')])\n",
    "print(f\"Removing {rows_to_remove} rows.\")\n",
    "\n",
    "# Drop the rows based on conditions\n",
    "diabetes = diabetes.drop(diabetes[(diabetes['admission_source_id'] == 13) ^ \n",
    "                                  (diabetes['payer_code'] == 'FR')].index)\n",
    "\n",
    "print(f\"Updated dimensions: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check dtype uniformity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "print(f\"\\nData information: {diabetes.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get updated list\n",
    "num_cols = diabetes.select_dtypes(include='int64')\n",
    "\n",
    "# Check column values, correspond to dtypes\n",
    "for cat in num_cols.columns:\n",
    "    print(f\"\\nColumn: {cat} values: {diabetes[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change numerical columns to categoricals\n",
    "\n",
    "Columns `admission_type_id`, `discharge_disposition_id` and `admission_source_id`are not numerical columns. They are categorical columns because their values represent distinct types of admissions or sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change columns type\n",
    "cols_to_change = [\"admission_type_id\",\"discharge_disposition_id\", \"admission_source_id\"]\n",
    "diabetes[cols_to_change] =  diabetes[cols_to_change].astype(str)\n",
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize memory use changing object to string\n",
    "categorical_cols = diabetes.select_dtypes('object').columns.tolist()\n",
    "\n",
    "# Check column values, correspond to dtypes\n",
    "for cat in categorical_cols:\n",
    "    print(f\"\\nColumn: {cat} values: {diabetes[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check categorical column pair relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# get categorical column pairs\n",
    "categorical_col_pair = list(itertools.combinations(categorical_cols, 2))       \n",
    "\n",
    "# visualize data relations\n",
    "for pair in categorical_col_pair:\n",
    "    print(f\"\\n{pair[0]} distribution per {pair[1]}\")\n",
    "    print(f\"{diabetes.groupby(pair[0])[pair[1]].value_counts(dropna= False).unstack().fillna(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save preprocessed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create folder\n",
    "tmp_folder = \"./tmp_folder\"\n",
    "os.makedirs(tmp_folder, exist_ok=True)\n",
    "\n",
    "# save data\n",
    "diabetes.to_parquet(os.path.join(tmp_folder,\"preprocessed_file.parquet\"),engine=\"pyarrow\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
