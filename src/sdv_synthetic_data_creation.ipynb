{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDV SYNTHETIC DATA GENERATION\n",
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "'''# metadata \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.variables) '''\n",
    "  \n",
    "# fetch dataset \n",
    "diabetes_130_us_hospitals_for_years_1999_2008 = fetch_ucirepo(id=296) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = diabetes_130_us_hospitals_for_years_1999_2008.data.features \n",
    "y = diabetes_130_us_hospitals_for_years_1999_2008.data.targets \n",
    "\n",
    "# create complete real_data\n",
    "diabetes = pd.DataFrame(X)\n",
    "diabetes[\"readmitted\"] = y\n",
    "\n",
    "# visualize data\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Dimension: {diabetes.shape}\")\n",
    "\n",
    "# data information\n",
    "print(f\"\\nData information: {diabetes.info()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect sensitive columns by intuition by their name\n",
    "print(f\"\\columns: {diabetes.columns}\\n\")\n",
    "\n",
    "# identify identity sensible data: \n",
    "sensitive_column_names = ['race', 'gender', 'weight', 'admission_type_id','discharge_disposition_id','admission_source_id','payer_code', 'medical_specialty']\n",
    "print(f\"\\nSensitive columns: {sensitive_column_names}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE COLUMN: check columns values & distribution\n",
    "for col in diabetes.columns:\n",
    "    print(f\"\\n\\nColumn: {col}\")\n",
    "    \n",
    "    # Get value counts of data\n",
    "    val_counts = diabetes[col].value_counts(dropna = False)   \n",
    "\n",
    "    # prepare to print more pretty way\n",
    "    counts_df = pd.DataFrame({'Items': val_counts})    \n",
    "\n",
    "    # Print \n",
    "    print(counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that some sensitive data may allow the re-identification of patients. Let's check whether that is really the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check '>200' weight data\n",
    "big_weights = diabetes[diabetes[\"weight\"] == '>200']\n",
    "big_weights = big_weights.sort_values(\"age\")\n",
    "big_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that `k-anonymity` rule is not met, reclasifying the weight values we could gain anonymity? Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' NEW WEIGTH CLASSIFICATION\n",
    "[0-100) == [0-25) & [25-50) & [50-75) & [75-100) \n",
    "> 100 ==  [100-125) & [125-150) & [150-175) & [175-200) & '>200'\n",
    "nan\n",
    "'''\n",
    "\n",
    "# Change weight ranges to gain anonymity\n",
    "diabetes1 = diabetes.copy()\n",
    "diabetes1.loc[diabetes1[\"weight\"].isin(['[0-25)', '[25-50)', '[50-75)', '[75-100)']), \"weight\"] = \"[0-100)\"\n",
    "diabetes1.loc[diabetes1[\"weight\"].isin(['[100-125)', '[125-150)', '[150-175)', '[175-200)','>200']), \"weight\"] = \"> 100\"\n",
    "\n",
    "# validating that only 3 values exists\n",
    "print(f\"New weight values:{diabetes1.weight.unique()}\")\n",
    "\n",
    "# SINGLE COLUMN: check after reajust weight\n",
    "for col in diabetes1.columns:\n",
    "    print(f\"\\n\\nColumn: {col}\")\n",
    "    \n",
    "    # Get value counts of data\n",
    "    val_counts = diabetes1[col].value_counts(dropna = False)   \n",
    "\n",
    "    # prepare to print more pretty way\n",
    "    counts_df = pd.DataFrame({'Items': val_counts})    \n",
    "\n",
    "    # Print \n",
    "    print(counts_df)\n",
    "\n",
    "# seems to be better distributed lets mantain this change\n",
    "diabetes = diabetes1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the data pairs to see if re-identification is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "# COLUMN PAIRS: create pairs, only with sensitive data\n",
    "column_pairs = list(itertools.combinations(sensitive_column_names, 2))\n",
    "\n",
    "# Dictionary to keep track of problematic rows\n",
    "special_pairs = {}\n",
    "count =0\n",
    "for val in column_pairs:\n",
    "    data_crosstab = pd.crosstab(diabetes[val[0]], \n",
    "                            diabetes[val[1]],  \n",
    "                            margins = False) \n",
    "    \n",
    "    # Check if any row in the crosstab has only 1 value\n",
    "    #print(f\"\\nCross_data: {data_crosstab}\")\n",
    "    conflicted_value_column = data_crosstab.apply(lambda row: row[row == 1].index.tolist(), axis=1)\n",
    "\n",
    "    # Filter only rows where the conflicted column is found (non-empty lists)\n",
    "    conflicted_value_column = conflicted_value_column[conflicted_value_column.apply(len) > 0]\n",
    "\n",
    "    if any(conflicted_value_column.apply(len) == 1):\n",
    "        #print(f\"conflicted_value_column: {conflicted_value_column}\")\n",
    "        # complete dictionary\n",
    "        count+=1\n",
    "        special_attention = {}\n",
    "        for index, columns in conflicted_value_column.items():\n",
    "            if len(columns)==1:\n",
    "                special_attention[val[0]] = index\n",
    "                special_attention[val[1]] = columns     \n",
    "                #print(f\"special_attention: {special_attention}\")\n",
    "                \n",
    "                # add to principal dictionary    \n",
    "                special_pairs[val] = special_attention\n",
    "                #print(f\"special_pairs: {special_pairs}\")\n",
    "            \n",
    "# visualize columns  \n",
    "print(f\"From: {len(column_pairs)} pairs conflictive are: {count}\")\n",
    "for key in special_pairs.keys():\n",
    "      print(f\"Check: {special_pairs.get(key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 'Unknown/Invalid' gender data\n",
    "unknown_gender = diabetes[diabetes[\"gender\"] == 'Unknown/Invalid']\n",
    "unknown_gender = unknown_gender.sort_values(\"age\")\n",
    "unknown_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since 'Unknown/Invalid' gender data not met k-anonymity rule, as first glance removing those values seems reasonable as only there are 3 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "weights = diabetes[\"weight\"].unique()\n",
    "\n",
    "# weight and age relation\n",
    "for w in weights:\n",
    "    filt1 = diabetes[diabetes[\"weight\"] == w]\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=\"race\", ax = ax)\n",
    "    ax.set_title(f\"Race distribution by Weight value:{w}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a quick glance seems that only some registries has weight values per age. Let's dive in this relations before create blindly synth data.\n",
    "\n",
    "EXPLORE REAL DATA VISUALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# weight and age relation\n",
    "for w in weights:\n",
    "    filt1 = diabetes1[diabetes1[\"weight\"] == w]\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=\"age\", ax = ax)\n",
    "    ax.set_title(f\"Age distribution by Weight value:{w}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight and age relation\n",
    "for w in weights:\n",
    "    filt1 = diabetes1[diabetes1[\"weight\"] == w]\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=\"age\", ax = ax)\n",
    "    ax.set_title(f\"Age distribution by Weight value:{w}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# visualizing data distribution\n",
    "for col in diabetes.columns:\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=col, ax = ax)\n",
    "    ax.set_title(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE SYNTHETIZER & SYNTHETIC DATA WITH SDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform `diabetes` dataframe `SingleTableMetadata` data type \n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "\n",
    "# Automatically detect metadata from the actual DataFrame\n",
    "metadata.detect_from_dataframe(diabetes)\n",
    "\n",
    "# Change dtype of \"_id\" columns. Threat as categorical instead of numerical\n",
    "for column_name in metadata.columns:\n",
    "    if '_id' in column_name:\n",
    "        metadata.update_column(column_name, sdtype='categorical')\n",
    "\n",
    "# Check if metadata has been correctly generated\n",
    "print(metadata)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "\n",
    "synthesizer = GaussianCopulaSynthesizer(\n",
    "    metadata,\n",
    "    enforce_min_max_values=True,\n",
    "    enforce_rounding=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data to learn from real data\n",
    "synthesizer.fit(\n",
    "    data = diabetes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data (same dimensions) based on learned model\n",
    "synthetic_data = synthesizer.sample(\n",
    "    num_rows=diabetes.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE SYNTHETIC DATA AND VALIDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Real dimension: {diabetes.shape}\")\n",
    "print(f\"Synth dimension: {synthetic_data.shape}\")\n",
    "\n",
    "# data information\n",
    "print(f\"\\n\\nReal data information: {diabetes.info()}\")\n",
    "print(f\"Synth data information: {synthetic_data.info()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare values creation\n",
    "for col in diabetes.columns:\n",
    "    print(f\"\\n\\nColumn: {col}\")\n",
    "    \n",
    "    # Get value counts for both real and synthetic data\n",
    "    real_counts = diabetes[col].value_counts()\n",
    "    synth_counts = synthetic_data[col].value_counts()\n",
    "    # Combine the counts to ensure all categories are represented in both datasets\n",
    "    combined_counts = pd.DataFrame({'Real': real_counts, 'Synthetic': synth_counts}).fillna(0)\n",
    "    \n",
    "    # Print the combined counts for easy comparison\n",
    "    print(combined_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CORRELATION MATRIX\n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "corr_r = diabetes.corr()\n",
    "corr_s = synthetic_data.corr()\n",
    "sns.heatmap(corr_r, \n",
    "            xticklabels=corr_r.columns.values,\n",
    "            yticklabels=corr_r.columns.values,\n",
    "            cmap=\"Blues\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[0])\n",
    "sns.heatmap(corr_s, \n",
    "            xticklabels=corr_s.columns.values,\n",
    "            yticklabels=corr_s.columns.values,\n",
    "            cmap=\"Greens\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[1])\n",
    "ax[0].set_title(\"REAL\")\n",
    "ax[1].set_title(\"SYNTH\")\n",
    "plt.tight_layout()     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sensitive data\n",
    "sensitive_column_names = ['race', 'gender', 'age','payer_code', 'medical_specialty']\n",
    "\n",
    "# understanding columns values\n",
    "for col in sensitive_column_names:\n",
    "    print(f\"\\n\\nReal column: {col} has values: {diabetes[col].unique()}\")\n",
    "    print(f\"Synth column: {col} has values: {synthetic_data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE SYNTHETIZER & SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create save folder\n",
    "synth_folder = os.path.join(\"./\",\"synthetic_data\")\n",
    "os.makedirs(synth_folder, exist_ok = True) \n",
    "\n",
    "# save synth generator \n",
    "synthesizer.save(os.path.join(synth_folder, \"sdv_synthesizer.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save synthetic data\n",
    "synthetic_data.to_parquet(os.path.join(synth_folder,\"sdv_synth.parquet\"), engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
