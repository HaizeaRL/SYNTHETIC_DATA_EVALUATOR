{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDV SYNTHETIC DATA GENERATION\n",
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "'''# metadata \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.variables) '''\n",
    "  \n",
    "# fetch dataset \n",
    "diabetes_130_us_hospitals_for_years_1999_2008 = fetch_ucirepo(id=296) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = diabetes_130_us_hospitals_for_years_1999_2008.data.features \n",
    "y = diabetes_130_us_hospitals_for_years_1999_2008.data.targets \n",
    "\n",
    "# create complete real_data\n",
    "diabetes = pd.DataFrame(X)\n",
    "diabetes[\"readmitted\"] = y\n",
    "\n",
    "# visualize data\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE & PREPROCESS REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Dimension: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect sensitive columns by intuition by their name\n",
    "print(f\"\\columns: {diabetes.columns}\\n\")\n",
    "\n",
    "# identify identity sensible data: \n",
    "sensitive_column_names = ['race', 'gender', 'weight', 'admission_type_id','discharge_disposition_id','admission_source_id','payer_code', 'medical_specialty']\n",
    "print(f\"\\nSensitive columns: {sensitive_column_names}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check columns values & distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE COLUMN: check columns values & distribution\n",
    "def visualize_columns_distributions(df):\n",
    "    for col in df.columns:\n",
    "        print(f\"\\n\\nColumn: {col}\")\n",
    "\n",
    "        # Get value counts of data\n",
    "        val_counts = df[col].value_counts(dropna = False)   \n",
    "\n",
    "        # prepare to print more pretty way\n",
    "        counts_df = pd.DataFrame({'Items': val_counts})    \n",
    "\n",
    "        # Print \n",
    "        print(counts_df)\n",
    "    \n",
    "# call to columns_distibution function\n",
    "visualize_columns_distributions(diabetes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generalize 'Nan' race values to 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize Nan race as 'Other'\n",
    "import numpy as np\n",
    "diabetes.loc[diabetes[\"race\"].isin([np.nan ,'Other']), \"race\"] = \"Other\"\n",
    "\n",
    "# validate change\n",
    "diabetes.race.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Remove 'Unknown/Invalid' gender values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Unknown/Invalid' # only 3 registry, not possible to define gender, best option would be to remove them \n",
    "diabetes[diabetes['gender'] == 'Unknown/Invalid'] \n",
    "\n",
    "# removing  'Unknown/Invalid' gender data\n",
    "print(f\"Shape before drop: {diabetes.shape}\")\n",
    "diabetes = diabetes.drop(diabetes[diabetes[\"gender\"] == 'Unknown/Invalid'].index)\n",
    "\n",
    "# validating results (only 3 less)\n",
    "print(f\"Shape after drop: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check for null values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls per columns (percentage)\n",
    "diabetes.isna().sum() * 100 / len(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Drop \"weight\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove weight column form dataframe\n",
    "print(f\"Columns before remove {len(diabetes.columns)}\")\n",
    "print(f\"Columns:{diabetes.columns}\")\n",
    "diabetes = diabetes.drop('weight', axis=1)\n",
    "print(f\"Columns after remove {len(diabetes.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check for variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops columns without variability\n",
    "def columns_without_variability(data_frame):\n",
    "    '''\n",
    "     Function that is responsible to determine which columnns has no variability (those which has only 1 value).\n",
    "    '''\n",
    "    sobran = []\n",
    "\n",
    "    cols = data_frame.columns\n",
    "    for col in cols:\n",
    "        if len(data_frame[col].unique()) < 2:\n",
    "            sobran.append(col)\n",
    "\n",
    "    return sobran\n",
    "\n",
    "# obtener listado de columnas sin variabilidad en una lista\n",
    "cols_without_variability = columns_without_variability(diabetes)\n",
    "\n",
    "# remove columns without variabitly\n",
    "print(f\"Columns before remove {len(diabetes.columns)}\")\n",
    "print(f\"Columns:{diabetes.columns}\")\n",
    "diabetes = diabetes.drop(columns = cols_without_variability)\n",
    "print(f\"Columns after remove {len(diabetes.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check dtype uniformity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "print(f\"\\nData information: {diabetes.info()}\\n\")\n",
    "\n",
    "# Check column values, correspond to dtypes\n",
    "for cat in diabetes.columns:\n",
    "    print(f\"\\nColumn: {cat} values: {diabetes[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data codification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import itertools\n",
    "\n",
    "# function that determines singularization risk columns pairs\n",
    "def determine_singularization_risk(df, column_pairs):\n",
    "      # Dictionary to keep track of problematic rows\n",
    "      special_pairs = {}\n",
    "      count =0\n",
    "      for val in column_pairs:\n",
    "           data_crosstab = pd.crosstab(df[val[0]], \n",
    "                            df[val[1]],  \n",
    "                            margins = False) \n",
    "           # Check if any row in the crosstab has only 1 value\n",
    "           #print(f\"\\nCross_data: {data_crosstab}\")\n",
    "           conflicted_value_column = data_crosstab.apply(lambda row: row[row == 1].index.tolist(), axis=1)\n",
    "\n",
    "           # Filter only rows where the conflicted column is found (non-empty lists)\n",
    "           conflicted_value_column = conflicted_value_column[conflicted_value_column.apply(len) > 0]\n",
    "\n",
    "           if any(conflicted_value_column.apply(len) == 1):\n",
    "                 #print(f\"conflicted_value_column: {conflicted_value_column}\")\n",
    "                 # complete dictionary\n",
    "                 count+=1\n",
    "                 special_attention = {}\n",
    "                 for index, columns in conflicted_value_column.items():\n",
    "                       if len(columns)==1:\n",
    "                             special_attention[val[0]] = index\n",
    "                             special_attention[val[1]] = columns     \n",
    "                             #print(f\"special_attention: {special_attention}\")\n",
    "\n",
    "                             # add to principal dictionary    \n",
    "                             special_pairs[val] = special_attention\n",
    "                             #print(f\"special_pairs: {special_pairs}\")\n",
    "\n",
    "      return (special_pairs, count)\n",
    "      \n",
    "                \n",
    "# COLUMN PAIRS: create pairs, only with sensitive data\n",
    "column_pairs = list(itertools.combinations(sensitive_column_names, 2))                \n",
    "# function call\n",
    "special_pairs, count = determine_singularization_risk(diabetes1, column_pairs)               \n",
    " \n",
    "# visualize results\n",
    "print(f\"From: {len(column_pairs)} pairs conflictive are: {count}\")\n",
    "for key in special_pairs.keys():\n",
    "      print(f\"Check: {special_pairs.get(key)}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE REAL DATA VISUALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# visualizing data distribution\n",
    "for col in diabetes.columns:\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=col, ax = ax)\n",
    "    ax.set_title(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE SYNTHETIZER & SYNTHETIC DATA WITH SDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform `diabetes` dataframe `SingleTableMetadata` data type \n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "\n",
    "# Automatically detect metadata from the actual DataFrame\n",
    "metadata.detect_from_dataframe(diabetes)\n",
    "\n",
    "# Change dtype of \"_id\" columns. Threat as categorical instead of numerical\n",
    "for column_name in metadata.columns:\n",
    "    if '_id' in column_name:\n",
    "        metadata.update_column(column_name, sdtype='categorical')\n",
    "\n",
    "# Check if metadata has been correctly generated\n",
    "print(metadata)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "\n",
    "synthesizer = GaussianCopulaSynthesizer(\n",
    "    metadata,\n",
    "    enforce_min_max_values=True,\n",
    "    enforce_rounding=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data to learn from real data\n",
    "synthesizer.fit(\n",
    "    data = diabetes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data (same dimensions) based on learned model\n",
    "synthetic_data = synthesizer.sample(\n",
    "    num_rows=diabetes.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE SYNTHETIC DATA AND VALIDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Real dimension: {diabetes.shape}\")\n",
    "print(f\"Synth dimension: {synthetic_data.shape}\")\n",
    "\n",
    "# data information\n",
    "print(f\"\\n\\nReal data information: {diabetes.info()}\")\n",
    "print(f\"Synth data information: {synthetic_data.info()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare values creation\n",
    "for col in diabetes.columns:\n",
    "    print(f\"\\n\\nColumn: {col}\")\n",
    "    \n",
    "    # Get value counts for both real and synthetic data\n",
    "    real_counts = diabetes[col].value_counts()\n",
    "    synth_counts = synthetic_data[col].value_counts()\n",
    "    # Combine the counts to ensure all categories are represented in both datasets\n",
    "    combined_counts = pd.DataFrame({'Real': real_counts, 'Synthetic': synth_counts}).fillna(0)\n",
    "    \n",
    "    # Print the combined counts for easy comparison\n",
    "    print(combined_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CORRELATION MATRIX\n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "corr_r = diabetes.corr()\n",
    "corr_s = synthetic_data.corr()\n",
    "sns.heatmap(corr_r, \n",
    "            xticklabels=corr_r.columns.values,\n",
    "            yticklabels=corr_r.columns.values,\n",
    "            cmap=\"Blues\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[0])\n",
    "sns.heatmap(corr_s, \n",
    "            xticklabels=corr_s.columns.values,\n",
    "            yticklabels=corr_s.columns.values,\n",
    "            cmap=\"Greens\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[1])\n",
    "ax[0].set_title(\"REAL\")\n",
    "ax[1].set_title(\"SYNTH\")\n",
    "plt.tight_layout()     \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
