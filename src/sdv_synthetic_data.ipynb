{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDV SYNTHETIC DATA GENERATION\n",
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "'''# metadata \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.variables) '''\n",
    "  \n",
    "# fetch dataset \n",
    "diabetes_130_us_hospitals_for_years_1999_2008 = fetch_ucirepo(id=296) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = diabetes_130_us_hospitals_for_years_1999_2008.data.features \n",
    "y = diabetes_130_us_hospitals_for_years_1999_2008.data.targets \n",
    "\n",
    "# create complete real_data\n",
    "diabetes = pd.DataFrame(X)\n",
    "diabetes[\"readmitted\"] = y\n",
    "\n",
    "# visualize data\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE & PREPROCESS REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Dimension: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect sensitive columns by intuition by their name\n",
    "print(f\"\\columns: {diabetes.columns}\\n\")\n",
    "\n",
    "# identify identity sensible data: \n",
    "sensitive_column_names = ['race', 'gender', 'weight', 'admission_type_id','discharge_disposition_id','admission_source_id','payer_code', 'medical_specialty']\n",
    "print(f\"\\nSensitive columns: {sensitive_column_names}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check columns values & distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE COLUMN: check columns values & distribution\n",
    "def visualize_columns_distributions(df):\n",
    "    for col in df.columns:\n",
    "        print(f\"\\n\\nColumn: {col}\")\n",
    "\n",
    "        # Get value counts of data\n",
    "        val_counts = df[col].value_counts(dropna = False)   \n",
    "\n",
    "        # prepare to print more pretty way\n",
    "        counts_df = pd.DataFrame({'Items': val_counts})    \n",
    "\n",
    "        # Print \n",
    "        print(counts_df)\n",
    "    \n",
    "# call to columns_distibution function\n",
    "visualize_columns_distributions(diabetes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generalize 'Nan' race values to 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize Nan race as 'Other'\n",
    "import numpy as np\n",
    "diabetes.loc[diabetes[\"race\"].isin([np.nan ,'Other']), \"race\"] = \"Other\"\n",
    "\n",
    "# validate change\n",
    "diabetes.race.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Remove 'Unknown/Invalid' gender values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Unknown/Invalid' # only 3 registry, not possible to define gender, best option would be to remove them \n",
    "diabetes[diabetes['gender'] == 'Unknown/Invalid'] \n",
    "\n",
    "# removing  'Unknown/Invalid' gender data\n",
    "print(f\"Shape before drop: {diabetes.shape}\")\n",
    "diabetes = diabetes.drop(diabetes[diabetes[\"gender\"] == 'Unknown/Invalid'].index)\n",
    "\n",
    "# validating results (only 3 less)\n",
    "print(f\"Shape after drop: {diabetes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check for null values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls per columns (percentage)\n",
    "diabetes.isna().sum() * 100 / len(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Drop \"weight\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove weight column form dataframe 96.858387% null values\n",
    "print(f\"Columns before remove {len(diabetes.columns)}\")\n",
    "print(f\"Columns:{diabetes.columns}\")\n",
    "diabetes = diabetes.drop('weight', axis=1)\n",
    "print(f\"Columns after remove {len(diabetes.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check for variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops columns without variability\n",
    "def columns_without_variability(data_frame):\n",
    "    '''\n",
    "     Function that is responsible to determine which columnns has no variability (those which has only 1 value).\n",
    "    '''\n",
    "    sobran = []\n",
    "\n",
    "    cols = data_frame.columns\n",
    "    for col in cols:\n",
    "        if len(data_frame[col].unique()) < 2:\n",
    "            sobran.append(col)\n",
    "\n",
    "    return sobran\n",
    "\n",
    "# obtener listado de columnas sin variabilidad en una lista\n",
    "cols_without_variability = columns_without_variability(diabetes)\n",
    "\n",
    "# TODO!! HOBETU TESTUA remove columns without variabitly\n",
    "print(f\"Columns before remove {len(diabetes.columns)}\")\n",
    "print(f\"Columns:{diabetes.columns}\")\n",
    "diabetes = diabetes.drop(columns = cols_without_variability)\n",
    "print(f\"Columns after remove {len(diabetes.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check dtype uniformity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "print(f\"\\nData information: {diabetes.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical data comprobations\n",
    "num_cols = diabetes.select_dtypes(include='int64')\n",
    "\n",
    "# Check column values, correspond to dtypes\n",
    "for cat in num_cols.columns:\n",
    "    print(f\"\\nColumn: {cat} values: {diabetes[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change admission_type_id, discharge_disposition_id  &  admission_source_id  to categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admission_type_id, discharge_disposition_id  &  admission_source_id  are categorical no numericals. Change\n",
    "cols_to_change = [\"admission_type_id\",\"discharge_disposition_id\", \"admission_source_id\"]\n",
    "diabetes[cols_to_change] =  diabetes[cols_to_change].astype(object)\n",
    "\n",
    "# get updated list\n",
    "num_cols = diabetes.select_dtypes(include='int64')\n",
    "\n",
    "# Check column values, correspond to dtypes\n",
    "for cat in num_cols.columns:\n",
    "    print(f\"\\nColumn: {cat} values: {diabetes[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# visualizing data distribution\n",
    "for col in num_cols.columns:\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=col, ax = ax)\n",
    "    ax.set_title(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize memory use changing object to string\n",
    "categorical_cols = diabetes.select_dtypes('object').columns.tolist()\n",
    "\n",
    "# Check column values, correspond to dtypes\n",
    "for cat in categorical_cols:\n",
    "    print(f\"\\nColumn: {cat} values: {diabetes[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# get categorical column pairs\n",
    "categorical_col_pair = list(itertools.combinations(categorical_cols, 2))       \n",
    "\n",
    "# visualize data relations\n",
    "for pair in categorical_col_pair:\n",
    "    print(f\"\\n{pair[0]} distribution per {pair[1]}\")\n",
    "    print(f\"{diabetes.groupby(pair[0])[pair[1]].value_counts(dropna= False).unstack().fillna(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "diabetes.to_parquet(\"./refined_file.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE SYNTHETIZER & SYNTHETIC DATA WITH SDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO funtzio batetan\n",
    "# Transform `diabetes` dataframe `SingleTableMetadata` data type \n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "# recover refined or preprocessed file\n",
    "diabetes = pd.read_parquet(\"./refined_file.parquet\",engine=\"pyarrow\")\n",
    "\n",
    "# Automatically detect metadata from the actual DataFrame\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(diabetes)\n",
    "\n",
    "# Change dtype of \"_id\" columns. Threat as categorical instead of numerical\n",
    "for column_name in metadata.columns:\n",
    "    if '_id' in column_name:\n",
    "        metadata.update_column(column_name, sdtype='categorical')\n",
    "# Check if metadata has been correctly generated\n",
    "print(metadata)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "\n",
    "#TODO dena funtzio batetan!\n",
    "synthesizer = GaussianCopulaSynthesizer(\n",
    "    metadata,\n",
    "    enforce_min_max_values=True,\n",
    "    enforce_rounding=True) \n",
    "\n",
    "# train data to learn from real data\n",
    "synthesizer.fit(\n",
    "    data = diabetes\n",
    ")\n",
    "\n",
    "# create new data (same dimensions) based on learned model\n",
    "synthetic_data = synthesizer.sample(\n",
    "    num_rows=diabetes.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE SYNTHETIC DATA AND VALIDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Real dimension: {diabetes.shape}\")\n",
    "print(f\"Synth dimension: {synthetic_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information from both datasets\n",
    "real_data_info = pd.DataFrame({\n",
    "    'Column': diabetes.columns,\n",
    "    'Real Non-Null Count':diabetes.notnull().sum()\n",
    "    \n",
    "})\n",
    "\n",
    "# For synthetic data\n",
    "synthetic_data_info = pd.DataFrame({\n",
    "    'Column': synthetic_data.columns,\n",
    "    'Synthetic Non-Null Count':synthetic_data.notnull().sum()\n",
    "})\n",
    "\n",
    "# Merge the two DataFrames on the 'Column' name\n",
    "comparison = pd.merge(real_data_info, synthetic_data_info, on='Column', how='outer')\n",
    "\n",
    "# Print comparison table\n",
    "print(\"Comparison of Real and Synthetic Data:\")\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check mayor differences and see how to improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare and detect considerable differences\n",
    "# set threshold\n",
    "threshold = 0.10\n",
    "\n",
    "# Initialize the list\n",
    "columns_with_differences = []\n",
    "\n",
    "for col in diabetes.columns:\n",
    "    print(f\"\\n\\nColumn: {col}\")\n",
    "    \n",
    "    # Get value counts for both real and synthetic data\n",
    "    real_counts = diabetes[col].value_counts()\n",
    "    synth_counts = synthetic_data[col].value_counts()\n",
    "    \n",
    "    # Combine the counts to ensure all categories are represented in both datasets\n",
    "    combined_counts = pd.DataFrame({'Real': real_counts, 'Synthetic': synth_counts}).fillna(0)\n",
    "    \n",
    "    # Compute proportions\n",
    "    total_real = combined_counts['Real'].sum()\n",
    "    total_synthetic = combined_counts['Synthetic'].sum()\n",
    "    combined_counts['Real_Proportion'] = combined_counts['Real'] / total_real\n",
    "    combined_counts['Synthetic_Proportion'] = combined_counts['Synthetic'] / total_synthetic\n",
    "    \n",
    "    # Compute absolute and relative differences\n",
    "    combined_counts['Absolute_Difference'] = combined_counts['Real_Proportion'] - combined_counts['Synthetic_Proportion']\n",
    "    combined_counts['Relative_Difference'] = combined_counts['Absolute_Difference'] / combined_counts['Real_Proportion'].replace(0, 1)  # Avoid division by zero\n",
    "    \n",
    "    # Print the combined counts for easy comparison\n",
    "    print(combined_counts)\n",
    "    \n",
    "    # Check if any relative difference exceeds the threshold\n",
    "    if (combined_counts['Relative_Difference'].abs() > threshold).any():\n",
    "        columns_with_differences.append(col)\n",
    "        print(f\"** Significant differences detected in column: {col} **\")\n",
    "\n",
    "# Report columns with considerable differences\n",
    "print(f\"\\nFrom: {len(diabetes.columns)} has considerable differences: {len(columns_with_differences)}\")\n",
    "print(\"\\nColumns with considerable differences between real and synthetic data:\")\n",
    "print(columns_with_differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check differences visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loop columns with differences and visualize in same plot\n",
    "for col in columns_with_differences:\n",
    "    real_counts = diabetes[col].value_counts().to_dict()\n",
    "    synthetic_counts = synthetic_data[col].value_counts().to_dict()\n",
    "\n",
    "    # Plot for Real Data\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(real_counts.keys(), real_counts.values(), alpha=0.7, label='Real Data')\n",
    "\n",
    "    # Plot for Synthetic Data\n",
    "    plt.bar(synthetic_counts.keys(), synthetic_counts.values(), alpha=0.7, label='Synthetic Data')\n",
    "\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title(f'Comparison of {col} distribution')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CORRELATION MATRIX\n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "corr_r = diabetes.corr()\n",
    "corr_s = synthetic_data.corr()\n",
    "sns.heatmap(corr_r, \n",
    "            xticklabels=corr_r.columns.values,\n",
    "            yticklabels=corr_r.columns.values,\n",
    "            cmap=\"Blues\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[0])\n",
    "sns.heatmap(corr_s, \n",
    "            xticklabels=corr_s.columns.values,\n",
    "            yticklabels=corr_s.columns.values,\n",
    "            cmap=\"Greens\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[1])\n",
    "ax[0].set_title(\"REAL\")\n",
    "ax[1].set_title(\"SYNTH\")\n",
    "plt.tight_layout()     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADJUST REAL DATA\n",
    "\n",
    "Adjust the frequencies of categories in the real data to match the desired proportions. This may involve oversampling underrepresented categories or undersampling overrepresented ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def adjust_data_distribution(df, col):\n",
    "    \"\"\"\n",
    "    Adjust the distribution of a specific column in the DataFrame to match its real proportions.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        col (str): The column name to adjust.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with adjusted distribution for the specified column.\n",
    "    \"\"\"\n",
    "    real_proportions = df[col].value_counts(normalize=True)\n",
    "    adjusted_real_df = pd.DataFrame()\n",
    "    \n",
    "    for value, proportion in real_proportions.items():\n",
    "        current_count = df[df[col] == value].shape[0]\n",
    "        target_count = int(proportion * len(df))\n",
    "        \n",
    "        if target_count > current_count:\n",
    "            # Oversample\n",
    "            sample_df = df[df[col] == value]\n",
    "            sampled_df = resample(sample_df, replace=True, n_samples=target_count - current_count)\n",
    "            adjusted_real_df = pd.concat([adjusted_real_df, sample_df, sampled_df])\n",
    "        elif target_count < current_count:\n",
    "            # Undersample\n",
    "            sampled_df = resample(df[df[col] == value], replace=False, n_samples=target_count)\n",
    "            adjusted_real_df = pd.concat([adjusted_real_df, sampled_df])\n",
    "        else:\n",
    "            # No adjustment\n",
    "            adjusted_real_df = pd.concat([adjusted_real_df, df[df[col] == value]])\n",
    "    \n",
    "    return adjusted_real_df\n",
    "\n",
    "def compare_distributions(real_df, adjusted_df, col):\n",
    "    \"\"\"\n",
    "    Compare the distributions of a specific column in the real and adjusted DataFrames with visualizations.\n",
    "    \n",
    "    Parameters:\n",
    "        real_df (pd.DataFrame): The original DataFrame.\n",
    "        adjusted_df (pd.DataFrame): The DataFrame with adjusted distribution.\n",
    "        col (str): The column name to compare.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Compute proportions for real and adjusted data\n",
    "    real_proportions = real_df[col].value_counts(normalize=True).sort_index()\n",
    "    adjusted_proportions = adjusted_df[col].value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    # Combine proportions into a DataFrame for easy comparison\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Real': real_proportions,\n",
    "        'Adjusted': adjusted_proportions\n",
    "    }).fillna(0)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    comparison_df.plot(kind='bar', width=0.8)\n",
    "    plt.title(f\"Comparison of Proportions for '{col}'\")\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(['Real', 'Adjusted'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate differences\n",
    "    comparison_df['Absolute_Difference'] = comparison_df['Real'] - comparison_df['Adjusted']\n",
    "    comparison_df['Relative_Difference'] = comparison_df['Absolute_Difference'] / comparison_df['Real'].replace(0, 1)  # Avoid division by zero\n",
    "\n",
    "    # Print comparison\n",
    "    print(f\"\\nComparison of Proportions for column '{col}':\")\n",
    "    print(comparison_df)\n",
    "    \n",
    "    # Optional: Highlight significant differences\n",
    "    significant_diff = comparison_df[comparison_df['Relative_Difference'].abs() > 0.1]\n",
    "    if not significant_diff.empty:\n",
    "        print(\"\\nSignificant Differences:\")\n",
    "        print(significant_diff)\n",
    "\n",
    "# Example usage for each column\n",
    "for col in diabetes.columns:\n",
    "    print(f\"\\nProcessing column: {col}\")\n",
    "    \n",
    "    # Adjust the real data\n",
    "    adjusted_real_df = adjust_data_distribution(diabetes, col)\n",
    "    \n",
    "    # Compare distributions\n",
    "    compare_distributions(diabetes, adjusted_real_df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize adjusted real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO AJUST!!\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def min_max_normalize(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "    return normalized_df\n",
    "\n",
    "# Example usage\n",
    "normalized_df = min_max_normalize(adjusted_real_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "normalized_df.to_parquet(\"./adjusted_and_normalized.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RE-CREATE SYNTH DATA AND VALIDATE PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO METADATA funtzioari deitu konpondutako dataset-akin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SYNTH SORRERA funtzioari deitu konpondutako dataset-akin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
