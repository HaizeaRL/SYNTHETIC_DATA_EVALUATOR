{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDV SYNTHETIC DATA GENERATION\n",
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "'''# metadata \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(diabetes_130_us_hospitals_for_years_1999_2008.variables) '''\n",
    "  \n",
    "# fetch dataset \n",
    "diabetes_130_us_hospitals_for_years_1999_2008 = fetch_ucirepo(id=296) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = diabetes_130_us_hospitals_for_years_1999_2008.data.features \n",
    "y = diabetes_130_us_hospitals_for_years_1999_2008.data.targets \n",
    "\n",
    "# create complete real_data\n",
    "diabetes = pd.DataFrame(X)\n",
    "diabetes[\"readmitted\"] = y\n",
    "\n",
    "# visualize data\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Dimension: {diabetes.shape}\")\n",
    "\n",
    "# data information\n",
    "print(f\"\\nData information: {diabetes.info()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect sensitive columns by intuition by their name\n",
    "print(f\"\\columns: {diabetes.columns}\\n\")\n",
    "\n",
    "# identify identity sensible data: \n",
    "sensitive_column_names = ['race', 'gender', 'weight', 'admission_type_id','discharge_disposition_id','admission_source_id','payer_code', 'medical_specialty']\n",
    "print(f\"\\nSensitive columns: {sensitive_column_names}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE COLUMN: check columns values & distribution\n",
    "def visualize_columns_distributions(df):\n",
    "    for col in df.columns:\n",
    "        print(f\"\\n\\nColumn: {col}\")\n",
    "\n",
    "        # Get value counts of data\n",
    "        val_counts = df[col].value_counts(dropna = False)   \n",
    "\n",
    "        # prepare to print more pretty way\n",
    "        counts_df = pd.DataFrame({'Items': val_counts})    \n",
    "\n",
    "        # Print \n",
    "        print(counts_df)\n",
    "    \n",
    "# call to columns_distibution function\n",
    "visualize_columns_distributions(diabetes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that some sensitive data may allow the re-identification of patients. Let's check whether that is really the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check '>200' weight data\n",
    "big_weights = diabetes[diabetes[\"weight\"] == '>200']\n",
    "big_weights = big_weights.sort_values(\"age\")\n",
    "big_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that `k-anonymity` rule is not met, reclasifying the weight values we could gain anonymity? Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' NEW WEIGTH CLASSIFICATION\n",
    "[0-100) == [0-25) & [25-50) & [50-75) & [75-100) \n",
    "> 100 ==  [100-125) & [125-150) & [150-175) & [175-200) & '>200'\n",
    "nan\n",
    "'''\n",
    "\n",
    "# Change weight ranges to gain anonymity\n",
    "diabetes1 = diabetes.copy()\n",
    "diabetes1.loc[diabetes1[\"weight\"].isin(['[0-25)', '[25-50)', '[50-75)', '[75-100)']), \"weight\"] = \"[0-100)\"\n",
    "diabetes1.loc[diabetes1[\"weight\"].isin(['[100-125)', '[125-150)', '[150-175)', '[175-200)','>200']), \"weight\"] = \"> 100\"\n",
    "\n",
    "# validating that only 3 values exists\n",
    "print(f\"New weight values:{diabetes1.weight.unique()}\")\n",
    "\n",
    "# call to columns_distibution function\n",
    "visualize_columns_distributions(diabetes1)    \n",
    "\n",
    "# seems to be better distributed lets mantain this change\n",
    "diabetes = diabetes1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the data pairs to see if re-identification is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# function that determines singularization risk columns pairs\n",
    "def determine_singularization_risk(df, column_pairs):\n",
    "      # Dictionary to keep track of problematic rows\n",
    "      special_pairs = {}\n",
    "      count =0\n",
    "      for val in column_pairs:\n",
    "           data_crosstab = pd.crosstab(df[val[0]], \n",
    "                            df[val[1]],  \n",
    "                            margins = False) \n",
    "           # Check if any row in the crosstab has only 1 value\n",
    "           #print(f\"\\nCross_data: {data_crosstab}\")\n",
    "           conflicted_value_column = data_crosstab.apply(lambda row: row[row == 1].index.tolist(), axis=1)\n",
    "\n",
    "           # Filter only rows where the conflicted column is found (non-empty lists)\n",
    "           conflicted_value_column = conflicted_value_column[conflicted_value_column.apply(len) > 0]\n",
    "\n",
    "           if any(conflicted_value_column.apply(len) == 1):\n",
    "                 #print(f\"conflicted_value_column: {conflicted_value_column}\")\n",
    "                 # complete dictionary\n",
    "                 count+=1\n",
    "                 special_attention = {}\n",
    "                 for index, columns in conflicted_value_column.items():\n",
    "                       if len(columns)==1:\n",
    "                             special_attention[val[0]] = index\n",
    "                             special_attention[val[1]] = columns     \n",
    "                             #print(f\"special_attention: {special_attention}\")\n",
    "\n",
    "                             # add to principal dictionary    \n",
    "                             special_pairs[val] = special_attention\n",
    "                             #print(f\"special_pairs: {special_pairs}\")\n",
    "\n",
    "      return (special_pairs, count)\n",
    "      \n",
    "                \n",
    "# COLUMN PAIRS: create pairs, only with sensitive data\n",
    "column_pairs = list(itertools.combinations(sensitive_column_names, 2))                \n",
    "# function call\n",
    "special_pairs, count = determine_singularization_risk(diabetes, column_pairs)               \n",
    " \n",
    "# visualize results\n",
    "print(f\"From: {len(column_pairs)} pairs conflictive are: {count}\")\n",
    "for key in special_pairs.keys():\n",
    "      print(f\"Check: {special_pairs.get(key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for singularization risks to determine the appropriate actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 'Unknown/Invalid' gender data\n",
    "diabetes[diabetes['gender'] == 'Unknown/Invalid'] # only 3 registry, not possible to define gender, remove\n",
    "\n",
    "# removing  'Unknown/Invalid' gender data\n",
    "print(f\"Shape before drop: {diabetes.shape}\")\n",
    "diabetes1 = diabetes.drop(diabetes[diabetes[\"gender\"] == 'Unknown/Invalid'].index)\n",
    "\n",
    "# validating results (only 3 less)\n",
    "print(f\"Shape after drop: {diabetes1.shape}\")\n",
    "\n",
    "# assing \"diabetes\" name again\n",
    "diabetes = diabetes1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to generalize even more `age` column to see if singularization risks is minorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New weight values:['[0-20)' '[20-40)' '[40-60)' '[60-80)' '[80-100)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[60-80)     48548\n",
       "[40-60)     26941\n",
       "[80-100)    19990\n",
       "[20-40)      5432\n",
       "[0-20)        852\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' New Columns: age\n",
    "[0-20) == [0-10) & [10-20)\n",
    "[20-40) == [20-30) & [30-40)\n",
    "[40-60) == [40-50) & [50-60)\n",
    "[60-80) == [60-70) & [70-80)\n",
    "[80-100) == [80-90) & [90-100)\n",
    "'''\n",
    "\n",
    "# Change weight ranges to gain anonymity\n",
    "diabetes1 = diabetes.copy()\n",
    "diabetes1.loc[diabetes1[\"age\"].isin(['[0-10)' ,'[10-20)']), \"age\"] = \"[0-20)\"\n",
    "diabetes1.loc[diabetes1[\"age\"].isin(['[20-30)', '[30-40)']), \"age\"] = \"[20-40)\"\n",
    "diabetes1.loc[diabetes1[\"age\"].isin(['[40-50)' ,'[50-60)']), \"age\"] = \"[40-60)\"\n",
    "diabetes1.loc[diabetes1[\"age\"].isin(['[60-70)', '[70-80)']), \"age\"] = \"[60-80)\"\n",
    "diabetes1.loc[diabetes1[\"age\"].isin(['[80-90)', '[90-100)']), \"age\"] = \"[80-100)\"\n",
    "\n",
    "# validating that only 3 values exists\n",
    "print(f\"New weight values:{diabetes1.age.unique()}\")\n",
    "\n",
    "# call to columns_distibution function\n",
    "diabetes1.age.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if this generation would help to minimize the individualization risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race is Other and its discharge_disposition_id = 15?\n",
    "gender_age_weight = diabetes1[(diabetes1[\"race\"] == 'Other') & (diabetes1[\"discharge_disposition_id\"] == 15)][[\"gender\", \"age\", \"weight\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]]\n",
    "filter_data = gender_age_weight.iloc[0] \n",
    "\n",
    "#Male\t[40-60)\tNaN\t1\t15\t1\n",
    "#\n",
    "# check if generalization is possible\n",
    "diabetes2 = diabetes1[diabetes1[\"discharge_disposition_id\"]== 15]\n",
    "\n",
    "# filter by gender [[\"gender\", \"age\", \"weight\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]]\n",
    "diabetes3 =diabetes2[diabetes2[\"gender\"]== filter_data.gender]\n",
    "\n",
    "# filter by age [[\"gender\", \"age\", \"weight\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]]\n",
    "diabetes4 = diabetes3[diabetes3[\"age\"]== filter_data.age]\n",
    "\n",
    "# filter by admission_type_id [[\"gender\", \"age\", \"weight\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]]\n",
    "diabetes5 = diabetes4[diabetes4[\"admission_type_id\"]== filter_data.admission_type_id]\n",
    "\n",
    "# filter by discharge_disposition_id [[\"gender\", \"age\", \"weight\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]]\n",
    "diabetes5[diabetes5[\"discharge_disposition_id\"]== filter_data.discharge_disposition_id]\n",
    "\n",
    "# we will drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop individual\n",
    "diabetes2 = diabetes1.drop(diabetes1[(diabetes1[\"race\"] == 'Other') & (diabetes1[\"discharge_disposition_id\"] == 15)].index)\n",
    "\n",
    "#assign to same dataset\n",
    "diabetes1 = diabetes2\n",
    "\n",
    "# save file to continue checking other actions\n",
    "diabetes1.to_csv(\"./age_generalization1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'raceis Other and its payer_code = CH?\n",
    "#diabetes[(diabetes[\"race\"] == 'Other') & (diabetes[\"payer_code\"] == \"CH\")] # exist posibility to generalize?\n",
    "\n",
    "# race is Asian and its admission_type_id = 4?\n",
    "#diabetes[(diabetes[\"race\"] == 'Asian') & (diabetes[\"admission_type_id\"] == 4)] # exist posibility to generalize?\n",
    "\n",
    "# gender is Male and its payer_code = \"FR\"?\n",
    "#diabetes[(diabetes[\"gender\"] == 'Male') & (diabetes[\"payer_code\"] == \"FR\")] # exist posibility to generalize?\n",
    "\n",
    "# gender is Male and its discharge_disposition_id = 20?\n",
    "#diabetes[(diabetes[\"gender\"] == 'Male') & (diabetes[\"discharge_disposition_id\"] == 20)] # exist posibility to generalize?\n",
    "\n",
    "# gender is Female and its admission_source_id = 14?\n",
    "#diabetes[(diabetes[\"gender\"] == 'Female') & (diabetes[\"admission_source_id\"] == 14)] # exist posibility to generalize?\n",
    "\n",
    "# weight is > 100' and its admission_type_id = 5?\n",
    "#diabetes[(diabetes[\"weight\"] == '> 100') & (diabetes[\"admission_type_id\"] == 5)] # exist posibility to generalize?\n",
    "\n",
    "# weight is [0-100)' and its payer_code = CH?\n",
    "#diabetes[(diabetes[\"weight\"] == '[0-100)') & (diabetes[\"payer_code\"] == \"CH\")] # exist posibility to generalize?\n",
    "\n",
    "# weight is [0-100)' and its medical_specialty = CH?\n",
    "#diabetes[(diabetes[\"weight\"] == '[0-100)') & (diabetes[\"medical_specialty\"] == \"Dentistry\")] # exist posibility to generalize?\n",
    "\n",
    "# weight is > 100' and its admission_type_id = 5?\n",
    "#diabetes[(diabetes[\"weight\"] == '> 100') & (diabetes[\"admission_type_id\"] == 5)] # exist posibility to generalize?\n",
    "\n",
    "# admission_type_id is 7 and its discharge_disposition_id = 2?\n",
    "#diabetes[(diabetes[\"admission_type_id\"] == 7) & (diabetes[\"discharge_disposition_id\"] == 2)] # exist posibility to generalize?\n",
    "\n",
    "# admission_type_id is 6 and its admission_source_id = 8?\n",
    "#diabetes[(diabetes[\"admission_type_id\"] == 6) & (diabetes[\"admission_source_id\"] == 8)] # exist posibility to generalize?\n",
    "\n",
    "# admission_type_id is 2 and its payer_code = 'FR'?\n",
    "#diabetes[(diabetes[\"admission_type_id\"] == 2) & (diabetes[\"payer_code\"] == 'FR')] # exist posibility to generalize?\n",
    "\n",
    "# discharge_disposition_id is 28 and its admission_source_id = 4?\n",
    "#diabetes[(diabetes[\"discharge_disposition_id\"] == 28) & (diabetes[\"admission_source_id\"] == 4)] # exist posibility to generalize?\n",
    "\n",
    "# discharge_disposition_id is 25 and its payer_code = 'MD'?\n",
    "#diabetes[(diabetes[\"discharge_disposition_id\"] == 25) & (diabetes[\"payer_code\"] == 'MD')] # exist posibility to generalize?\n",
    "\n",
    "# discharge_disposition_id is 27 and its medical_specialty = 'Family/GeneralPractice'?\n",
    "#diabetes[(diabetes[\"discharge_disposition_id\"] == 27) & (diabetes[\"medical_specialty\"] == 'Family/GeneralPractice')] # exist posibility to generalize?\n",
    "\n",
    "# admission_source_id is 17 and its payer_code = 'MD'?\n",
    "#diabetes[(diabetes[\"admission_source_id\"] == 17) & (diabetes[\"payer_code\"] == 'WC')] # exist posibility to generalize?\n",
    "\n",
    "# admission_source_id is 22 and its medical_specialty = 'Family/GeneralPractice'?\n",
    "#diabetes[(diabetes[\"admission_source_id\"] == 22) & (diabetes[\"medical_specialty\"] == 'Orthopedics-Reconstructive')] # exist posibility to generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 'Unknown/Invalid' gender data not met k-anonymity rule, as first glance removing those values seems reasonable as only are 3 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before drop: (101766, 48)\n",
      "Shape after drop: (101763, 48)\n",
      "Diabetes shape: (101763, 48)\n",
      "\n",
      "From: 28 pairs conflictive are: 17\n",
      "Check: {'race': 'Asian', 'admission_type_id': [4]}\n",
      "Check: {'race': 'Other', 'discharge_disposition_id': [15]}\n",
      "Check: {'race': 'Other', 'payer_code': ['CH']}\n",
      "Check: {'gender': 'Male', 'discharge_disposition_id': [20]}\n",
      "Check: {'gender': 'Female', 'admission_source_id': [14]}\n",
      "Check: {'gender': 'Male', 'payer_code': ['FR']}\n",
      "Check: {'weight': '> 100', 'admission_type_id': [5]}\n",
      "Check: {'weight': '[0-100)', 'payer_code': ['CH']}\n",
      "Check: {'weight': '[0-100)', 'medical_specialty': ['Dentistry']}\n",
      "Check: {'admission_type_id': 7, 'discharge_disposition_id': [2]}\n",
      "Check: {'admission_type_id': 6, 'admission_source_id': [8]}\n",
      "Check: {'admission_type_id': 2, 'payer_code': ['FR']}\n",
      "Check: {'discharge_disposition_id': 28, 'admission_source_id': [4]}\n",
      "Check: {'discharge_disposition_id': 25, 'payer_code': ['MD']}\n",
      "Check: {'discharge_disposition_id': 27, 'medical_specialty': ['Family/GeneralPractice']}\n",
      "Check: {'admission_source_id': 17, 'payer_code': ['WC']}\n",
      "Check: {'admission_source_id': 22, 'medical_specialty': ['Orthopedics-Reconstructive']}\n"
     ]
    }
   ],
   "source": [
    "# removing  'Unknown/Invalid' gender data\n",
    "print(f\"Shape before drop: {diabetes.shape}\")\n",
    "diabetes1 = diabetes.drop(diabetes[diabetes[\"gender\"] == 'Unknown/Invalid'].index)\n",
    "\n",
    "# validating results (only 3 less)\n",
    "print(f\"Shape after drop: {diabetes1.shape}\")\n",
    "\n",
    "# assing \"diabetes\" name again\n",
    "diabetes = diabetes1\n",
    "\n",
    "# validating results (only 3 less)\n",
    "print(f\"Diabetes shape: {diabetes.shape}\")\n",
    "\n",
    "# check singularities again after remove\n",
    "special_pairs, count = determine_singularization_risk(diabetes, column_pairs)\n",
    "\n",
    "# visualize results  \n",
    "print(f\"\\nFrom: {len(column_pairs)} pairs conflictive are: {count}\")\n",
    "for key in special_pairs.keys():\n",
    "      print(f\"Check: {special_pairs.get(key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for singularization risks to determine the appropriate actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in csv to filter and determine actions better\n",
    "diabetes.to_csv(\"./singularization_risk.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both instances of race `Other` do not refer to the same person. The person with `\"discharge_disposition_id\" = 15` reflect a direct risk of singularization. A single person with this characteristic will not be sufficient for training any model, so removing this individual would be the best action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# current dimesion\n",
    "print(f\"current dimension: {diabetes.shape}\")\n",
    "\n",
    "# remove directly \"discharge_disposition_id\" = 15 individual\n",
    "diabetes = diabetes.drop(diabetes[(diabetes[\"race\"] == \"Other\") & (diabetes[\"discharge_disposition_id\"] == 15)].index)\n",
    "\n",
    "# validate dimension (1 less)\n",
    "print(f\"new_dimension: {diabetes.shape}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respecting the other person, it is advisable to check if they meet the k-anonymity standard by generalizing the `payer_code` to an `Nan` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corresponding line data to sort all other according to this columns and determine action\n",
    "gender_age_weight  = other[(other[\"race\"] == \"Other\") & (other[\"payer_code\"] == \"CH\")][[\"gender\", \"age\", \"weight\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]]\n",
    "filter_data = gender_age_weight.iloc[0]\n",
    "\n",
    "filter_data # Female\t[60-70)\tNaN\t1\t1\t7\n",
    "\n",
    "# filter by gender\n",
    "other[other[\"gender\"] == filter_data.gender]\n",
    "\n",
    "# filter by age\n",
    "other[other[\"age\"] == filter_data.age]\n",
    "\n",
    "# filter by weight\n",
    "other1 = other[other[\"admission_type_id\"] == filter_data.admission_type_id]\n",
    "\n",
    "other1.sort_values([\"gender\",\"age\"],inplace =True)\n",
    "\n",
    "# save data in csv to control better\n",
    "other1.to_csv(\"./other_singularization1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! by generalizing the `payer_code` to an `Nan` value we avoid this person singularity risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# actual value\n",
    "print(f\"actual value: {diabetes[(diabetes['race'] == 'Other') & (diabetes['payer_code'] == 'CH')]['payer_code']}\")\n",
    "\n",
    "# set NAN value\n",
    "diabetes.loc[(diabetes[\"race\"] == \"Other\") & (diabetes[\"payer_code\"] == \"CH\"), \"payer_code\"] = np.nan\n",
    "\n",
    "# no value\n",
    "print(f\"new value: {diabetes[(diabetes['race'] == 'Other') & (diabetes['payer_code'] == 'CH')]['payer_code']}\")\n",
    "\n",
    "# check singularities again after remove\n",
    "special_pairs, count = determine_singularization_risk(diabetes, column_pairs)\n",
    "\n",
    "# visualize results  \n",
    "print(f\"\\nFrom: {len(column_pairs)} pairs conflictive are: {count}\")\n",
    "for key in special_pairs.keys():\n",
    "      print(f\"Check: {special_pairs.get(key)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100721</th>\n",
       "      <td>Male</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>[0-100)</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender      age   weight  admission_type_id  discharge_disposition_id  \\\n",
       "100721   Male  [80-90)  [0-100)                  4                         6   \n",
       "\n",
       "        admission_source_id  \n",
       "100721                    7  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check race 'Asian' cases, tcan be avoido singularization problems refers to the same person?\n",
    "asians = diabetes[diabetes[\"race\"] == \"Asian\"]\n",
    "\n",
    "gender_age_weight  = asians[(asians[\"race\"] == \"Asian\") & (asians[\"admission_type_id\"] == 4)][[\"gender\", \"age\", \"weight\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]]\n",
    "\n",
    "gender_age_weight #Male\t[80-90)\t[0-100)\t4\t6\t7\n",
    "\n",
    "asians.to_csv(\"./asian_singularities.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "weights = diabetes[\"weight\"].unique()\n",
    "\n",
    "# weight and age relation\n",
    "for w in weights:\n",
    "    filt1 = diabetes[diabetes[\"weight\"] == w]\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=\"race\", ax = ax)\n",
    "    ax.set_title(f\"Race distribution by Weight value:{w}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a quick glance seems that only some registries has weight values per age. Let's dive in this relations before create blindly synth data.\n",
    "\n",
    "EXPLORE REAL DATA VISUALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# weight and age relation\n",
    "for w in weights:\n",
    "    filt1 = diabetes1[diabetes1[\"weight\"] == w]\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=\"age\", ax = ax)\n",
    "    ax.set_title(f\"Age distribution by Weight value:{w}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight and age relation\n",
    "for w in weights:\n",
    "    filt1 = diabetes1[diabetes1[\"weight\"] == w]\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=\"age\", ax = ax)\n",
    "    ax.set_title(f\"Age distribution by Weight value:{w}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# visualizing data distribution\n",
    "for col in diabetes.columns:\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    sns.countplot(data=diabetes, x=col, ax = ax)\n",
    "    ax.set_title(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE SYNTHETIZER & SYNTHETIC DATA WITH SDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform `diabetes` dataframe `SingleTableMetadata` data type \n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "\n",
    "# Automatically detect metadata from the actual DataFrame\n",
    "metadata.detect_from_dataframe(diabetes)\n",
    "\n",
    "# Change dtype of \"_id\" columns. Threat as categorical instead of numerical\n",
    "for column_name in metadata.columns:\n",
    "    if '_id' in column_name:\n",
    "        metadata.update_column(column_name, sdtype='categorical')\n",
    "\n",
    "# Check if metadata has been correctly generated\n",
    "print(metadata)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "\n",
    "synthesizer = GaussianCopulaSynthesizer(\n",
    "    metadata,\n",
    "    enforce_min_max_values=True,\n",
    "    enforce_rounding=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data to learn from real data\n",
    "synthesizer.fit(\n",
    "    data = diabetes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data (same dimensions) based on learned model\n",
    "synthetic_data = synthesizer.sample(\n",
    "    num_rows=diabetes.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE SYNTHETIC DATA AND VALIDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(f\"Real dimension: {diabetes.shape}\")\n",
    "print(f\"Synth dimension: {synthetic_data.shape}\")\n",
    "\n",
    "# data information\n",
    "print(f\"\\n\\nReal data information: {diabetes.info()}\")\n",
    "print(f\"Synth data information: {synthetic_data.info()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare values creation\n",
    "for col in diabetes.columns:\n",
    "    print(f\"\\n\\nColumn: {col}\")\n",
    "    \n",
    "    # Get value counts for both real and synthetic data\n",
    "    real_counts = diabetes[col].value_counts()\n",
    "    synth_counts = synthetic_data[col].value_counts()\n",
    "    # Combine the counts to ensure all categories are represented in both datasets\n",
    "    combined_counts = pd.DataFrame({'Real': real_counts, 'Synthetic': synth_counts}).fillna(0)\n",
    "    \n",
    "    # Print the combined counts for easy comparison\n",
    "    print(combined_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CORRELATION MATRIX\n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "corr_r = diabetes.corr()\n",
    "corr_s = synthetic_data.corr()\n",
    "sns.heatmap(corr_r, \n",
    "            xticklabels=corr_r.columns.values,\n",
    "            yticklabels=corr_r.columns.values,\n",
    "            cmap=\"Blues\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[0])\n",
    "sns.heatmap(corr_s, \n",
    "            xticklabels=corr_s.columns.values,\n",
    "            yticklabels=corr_s.columns.values,\n",
    "            cmap=\"Greens\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[1])\n",
    "ax[0].set_title(\"REAL\")\n",
    "ax[1].set_title(\"SYNTH\")\n",
    "plt.tight_layout()     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sensitive data\n",
    "sensitive_column_names = ['race', 'gender', 'age','payer_code', 'medical_specialty']\n",
    "\n",
    "# understanding columns values\n",
    "for col in sensitive_column_names:\n",
    "    print(f\"\\n\\nReal column: {col} has values: {diabetes[col].unique()}\")\n",
    "    print(f\"Synth column: {col} has values: {synthetic_data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE SYNTHETIZER & SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create save folder\n",
    "synth_folder = os.path.join(\"./\",\"synthetic_data\")\n",
    "os.makedirs(synth_folder, exist_ok = True) \n",
    "\n",
    "# save synth generator \n",
    "synthesizer.save(os.path.join(synth_folder, \"sdv_synthesizer.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save synthetic data\n",
    "synthetic_data.to_parquet(os.path.join(synth_folder,\"sdv_synth.parquet\"), engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
