{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDV SYNTHETIC DATA GENERATION\n",
    "\n",
    "## LOAD PREPROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# create folder\n",
    "tmp_folder = \"../results\"\n",
    "diabetes = pd.read_parquet(os.path.join(tmp_folder,\"preprocessed_file.parquet\"),engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE SYNTHETIZERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import CTGANSynthesizer, GaussianCopulaSynthesizer\n",
    "from scipy.stats import gamma, skew\n",
    "import numpy as np\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "def create_metadata(df):\n",
    "    \"\"\"\n",
    "    SingleTableMetadata type data creation. Obtains information directly from original dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        SingleTableMetadata: metadata to create synthetic data\n",
    "    \"\"\"\n",
    "    # Automatically detect metadata from the actual DataFrame\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(df)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "def create_CTGANSynthesizer (df, md):\n",
    "    \"\"\"\n",
    "    Creates CTGANSynthesizer type synthetizer, trains synthesizer with real data and creates new \n",
    "    synthetic data.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        md (SingleTableMetadata): Metadata of DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        sinthetizer (CTGANSynthesizer): returns trained synthesizer.\n",
    "    \"\"\"\n",
    "\n",
    "    # create synthesizer\n",
    "    synthesizer = CTGANSynthesizer(\n",
    "        md, # required\n",
    "        enforce_rounding=True,\n",
    "        epochs=100,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # train data to learn from real data\n",
    "    synthesizer.fit(\n",
    "        data = df\n",
    "    )\n",
    "\n",
    "    return synthesizer\n",
    "\n",
    "def create_numerical_colums_distribution(df):\n",
    "    \"\"\"\n",
    "    Function that generates numerical columns data distribution\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        num_distribution acording to distr distribution\n",
    "    \"\"\"\n",
    "    num_distribution = {}\n",
    "    num_cols = diabetes.select_dtypes(include='int64')  # only numerical columns  \n",
    "    for col in num_cols:\n",
    "        # Calculate the skewness \n",
    "        skewness = skew(df[col])\n",
    "        print(f\"\\nColumn: {col} skewness: {skewness}\")\n",
    "\n",
    "        if skewness > 0: # if  possitive gamma \n",
    "            gamma_params = gamma.fit(df[col])\n",
    "\n",
    "            # get params to configure \n",
    "            shape, loc, scale = gamma_params\n",
    "            print(f\"Gamma distribution parameters:\\nShape: {shape}, Loc: {loc}, Scale: {scale}\")\n",
    "\n",
    "            num_distribution[col] = \"gamma\"\n",
    "        else:\n",
    "            num_distribution[col] = \"gaussian_kde\"\n",
    "\n",
    "    return num_distribution\n",
    "\n",
    "def create_full_synthesizer(df, num_distr):\n",
    "    \"\"\"\n",
    "    Creates a synthesizer for categorical and gamma distributed columns.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        num_distr: Numerical columns data distribution.\n",
    "\n",
    "    Returns:\n",
    "        synthesizer_full: Synthesizer for categorical and gamma distributed columns.\n",
    "    \"\"\"\n",
    "    # Separate categorical and gamma distributed columns\n",
    "    categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "    gamma_cols = [col for col in df.columns if (col in num_distr.keys()) and (num_distr[col] == 'gamma')]\n",
    "    \n",
    "    # Create DataFrame for gamma distributed and categorical columns\n",
    "    df_full = df[categorical_cols + gamma_cols]\n",
    "    \n",
    "    # Filter metadata\n",
    "    filtered_md = create_metadata(df[categorical_cols + gamma_cols])\n",
    "    \n",
    "    # Create synthesizer for full DataFrame (categorical + gamma distributed)\n",
    "    synthesizer_full = GaussianCopulaSynthesizer(\n",
    "        filtered_md,\n",
    "        enforce_min_max_values=True,\n",
    "        enforce_rounding=True,\n",
    "        numerical_distributions={col: 'gamma' for col in gamma_cols}\n",
    "    )\n",
    "    synthesizer_full.fit(data=df_full)\n",
    "\n",
    "    return synthesizer_full\n",
    "\n",
    "def create_kde_synthesizer(df, num_distr, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Creates a synthesizer for columns that require gaussian_kde using batching.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.       \n",
    "        num_distr: Numerical columns data distribution.\n",
    "        batch_size (int): The size of each batch for fitting.\n",
    "\n",
    "    Returns:\n",
    "        synthesizer_kde: Synthesizer for columns that need gaussian_kde.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify columns that need gaussian_kde\n",
    "    kde_cols = [col for col in df.columns if (col in num_distr.keys()) and (num_distr[col] == \"gaussian_kde\")]\n",
    "    \n",
    "    # Filter metadata\n",
    "    filtered_md = create_metadata(df[kde_cols])\n",
    "    \n",
    "    # Create synthesizer for gaussian_kde columns only\n",
    "    synthesizer_kde = GaussianCopulaSynthesizer(\n",
    "        filtered_md,\n",
    "        enforce_min_max_values=True,\n",
    "        enforce_rounding=True,\n",
    "        numerical_distributions={col: 'gaussian_kde' for col in kde_cols}\n",
    "    )\n",
    "    \n",
    "    # Fit the synthesizer in batches to avoid memory crashes\n",
    "    for start in range(0, df.shape[0], batch_size):\n",
    "        end = start + batch_size\n",
    "        batch = df[kde_cols].iloc[start:end]\n",
    "        \n",
    "        # Fit the synthesizer with the current batch\n",
    "        synthesizer_kde.fit(data=batch)  # Cumulative Learning, accumulates knowledge about the data as it processes each batch.\n",
    "\n",
    "    return synthesizer_kde\n",
    "\n",
    "def generate_synthetic_data_by_2_synths(synth_full, synth_kde, num_rows):\n",
    "    \"\"\"\n",
    "    Generates synthetic data from both synthesizers.\n",
    "\n",
    "    Parameters:\n",
    "        synth_full: synthesizer for categorical and gamma distributed columns\n",
    "        synth_kde: synthesizer for gaussian_kde columns\n",
    "        num_rows: Number of rows for synthetic data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined synthetic data.\n",
    "    \"\"\"\n",
    "    # Generate synthetic data\n",
    "    synthetic_full = synth_full.sample(num_rows)    \n",
    "    synthetic_kde = synth_kde.sample(num_rows)\n",
    "\n",
    "    # Combine the dataframes, aligning by columns\n",
    "    synthetic_data = pd.concat([synthetic_full.reset_index(drop=True), synthetic_kde.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return synthetic_data\n",
    "\n",
    "def create_synth_data (df, synth):\n",
    "    \"\"\"\n",
    "    Generates synthetic data based on passed synthesizer.\n",
    "\n",
    "    Parameters:\n",
    "        synth: synthesizer \n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined synthetic data.\n",
    "    \"\"\"\n",
    "\n",
    "    # create new synth data\n",
    "    synthetic_data = synth.sample(\n",
    "        num_rows=df.shape[0]\n",
    "    )\n",
    "    \n",
    "    return synthetic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianCopulaSynthesizer\n",
    "\n",
    "#### Get numerical data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call num_distribution generator\n",
    "num_distribution = create_numerical_colums_distribution(diabetes)\n",
    "num_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthesizer\n",
    "\n",
    "Create synthesizer separately,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian_kde numerical data synthesizer only. Optimizing memory.\n",
    "synth_gcopula_kde = create_kde_synthesizer(diabetes, num_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest of the data\n",
    "synth_gcopula_rest = create_full_synthesizer(diabetes, num_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save synthesizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# save as joblib both synthesizers\n",
    "dump(synth_gcopula_kde, os.path.join(tmp_folder,'synth_kde.joblib'))\n",
    "dump(synth_gcopula_rest, os.path.join(tmp_folder,'synth_rest.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTGANSynthesizer\n",
    "\n",
    "#### Create synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call to gan_synthetizer \n",
    "metadata = create_metadata(diabetes)\n",
    "ctgan_synthesizer = create_CTGANSynthesizer (diabetes, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as joblib\n",
    "dump(ctgan_synthesizer, os.path.join(tmp_folder,'ctgan_synthesizer.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE SYNTHETIC DATA\n",
    "\n",
    "### With GaussianCopulaSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data composed by 2 synthesizer data.\n",
    "g_copula_synth_data = generate_synthetic_data_by_2_synths(synth_gcopula_rest, synth_gcopula_kde, diabetes.shape[0])\n",
    "\n",
    "# print result\n",
    "g_copula_synth_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save GaussianCopula synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save synthetic data\n",
    "g_copula_synth_data.to_parquet(os.path.join(tmp_folder,\"g_copula_synth_data.parquet\"),engine=\"pyarrow\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain synthetic data\n",
    "ctgan_synth_data = create_synth_data(diabetes, ctgan_synthesizer)\n",
    "\n",
    "# print result\n",
    "ctgan_synth_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save GaussianCTGAN synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save synthetic data\n",
    "ctgan_synth_data.to_parquet(os.path.join(tmp_folder,\"ctgan_synth_data.parquet\"),engine=\"pyarrow\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE THE RESULTED SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "\n",
    "# create evaluation report\n",
    "quality_gcopula = evaluate_quality(diabetes, g_copula_synth_data, metadata)  # GaussianCopula\n",
    "quality_ctgan = evaluate_quality(diabetes, ctgan_synth_data, metadata)  # CTGAN\n",
    "\n",
    "print(f\"Quality of GaussianCopula synthetic data: {quality_gcopula}\")\n",
    "print(f\"Quality of CTGAN synthetic data: {quality_ctgan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE REAL DATA WITH SYNTHETIC DATA\n",
    "\n",
    "### Compare dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Real dimension: {diabetes.shape}\")\n",
    "print(f\"Synth dimension: {synthetic_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare general data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information from both datasets\n",
    "real_data_info = pd.DataFrame({\n",
    "    'Column': diabetes.columns,\n",
    "    'Real Non-Null Count':diabetes.notnull().sum()\n",
    "})\n",
    "\n",
    "# For synthetic data\n",
    "synthetic_data_info = pd.DataFrame({\n",
    "    'Column': synthetic_data.columns,\n",
    "    'Synthetic Non-Null Count':synthetic_data.notnull().sum()\n",
    "})\n",
    "\n",
    "# Merge the two DataFrames on the 'Column' name\n",
    "comparison = pd.merge(real_data_info, synthetic_data_info, on='Column', how='outer')\n",
    "\n",
    "# Print comparison table\n",
    "print(\"Comparison of Real and Synthetic Data:\")\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data anonymization\n",
    "\n",
    "Check first N rows and their sensible columns values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect sensible columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify identity sensible data: \n",
    "sensitive_columns = ['race', 'gender', 'age', 'admission_type_id','discharge_disposition_id','admission_source_id','payer_code']\n",
    "print(f\"\\nSensitive columns: {sensitive_columns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sensible data anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Real: {diabetes[sensitive_columns].head()}\")\n",
    "print(f\"\\nSynthetic: {synthetic_data[sensitive_columns].head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for numeric data correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CORRELATION MATRIX\n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "corr_r = diabetes.corr()\n",
    "corr_s = synthetic_data.corr()\n",
    "sns.heatmap(corr_r, \n",
    "            xticklabels=corr_r.columns.values,\n",
    "            yticklabels=corr_r.columns.values,\n",
    "            cmap=\"Blues\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[0])\n",
    "sns.heatmap(corr_s, \n",
    "            xticklabels=corr_s.columns.values,\n",
    "            yticklabels=corr_s.columns.values,\n",
    "            cmap=\"Greens\",\n",
    "            annot=True,         # Display the correlation values in the cells\n",
    "            fmt=\".2f\", ax = ax[1])\n",
    "ax[0].set_title(\"REAL\")\n",
    "ax[1].set_title(\"SYNTH\")\n",
    "plt.tight_layout()     \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
